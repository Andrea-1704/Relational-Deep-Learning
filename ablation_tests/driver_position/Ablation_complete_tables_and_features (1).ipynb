{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea-1704/Pytorch_Geometric_tutorial/blob/main/train_model_baseline_f1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAnf26iN5QYQ"
      },
      "source": [
        "# Obiettivo\n",
        "Questo notebook segue il lavoro di Ablation sulle tabelle. L'obiettivo questa volta è quella di capire, per ogni tabella che consideremo nel dataset e per ogni sua features, quanto pesa la rimozione di qualche feature da quella tabella al fine di ridurre le colonne che la rete deve considerare per ogni specifico nodo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D3ONst6S0pI"
      },
      "source": [
        "# Libraries to install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zNziUzq9nTdU"
      },
      "outputs": [],
      "source": [
        "# !pip install torch==2.6.0+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "\n",
        "# !pip install pytorch_frame[full]==1.2.2\n",
        "# !pip install relbench[full]==1.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnQsMT_H0Cd5"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I4CRrrOj0Dyp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.tasks import get_task\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import torch_geometric\n",
        "import torch_frame\n",
        "from torch_geometric.seed import seed_everything\n",
        "from relbench.modeling.utils import get_stype_proposal\n",
        "from collections import defaultdict\n",
        "import requests\n",
        "from io import StringIO\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "import pyg_lib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JWVJkt7XmNa"
      },
      "source": [
        "#Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ObC7OswYXn6e"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def alignment_check(loader: NeighborLoader, expected_node_ids: torch.Tensor):\n",
        "    node_id_list = []\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        node_id_list.append(batch[task.entity_table].n_id.cpu())\n",
        "\n",
        "    actual_node_ids = torch.cat(node_id_list, dim=0)\n",
        "\n",
        "    assert len(actual_node_ids) == len(expected_node_ids), \"Mismatch nella lunghezza\"\n",
        "\n",
        "    if not torch.equal(actual_node_ids, expected_node_ids):\n",
        "        raise ValueError(\"Ordine dei nodi predetti diverso da val_table!\")\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nVP-uHSKYA5H"
      },
      "outputs": [],
      "source": [
        "def evaluate_performance(pred: np.ndarray, target_table, metrics) -> dict:\n",
        "    \"\"\"Custom evaluation function to replace task.evaluate.\"\"\"\n",
        "    target = target_table.df[task.target_col].to_numpy()\n",
        "\n",
        "    if len(pred) != len(target):\n",
        "        raise ValueError(\n",
        "            f\"The length of pred and target must be the same (got \"\n",
        "            f\"{len(pred)} and {len(target)}, respectively).\"\n",
        "        )\n",
        "\n",
        "    results = {}\n",
        "    for metric_fn in metrics:\n",
        "        if metric_fn.__name__ == \"rmse\":\n",
        "            results[\"rmse\"] = np.sqrt(np.mean((target - pred)**2))\n",
        "        else:\n",
        "            results[metric_fn.__name__] = metric_fn(target, pred)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lipjiwyaYEJU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_on_train_during_training() -> float:\n",
        "    model.eval()\n",
        "    pred_list, target_list = [], []\n",
        "\n",
        "    for batch in loader_dict[\"train\"]:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch, task.entity_table)\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "        target_list.append(batch[task.entity_table].y.detach().cpu())\n",
        "\n",
        "    pred_all = torch.cat(pred_list, dim=0).numpy()\n",
        "    target_all = torch.cat(target_list, dim=0).numpy()\n",
        "\n",
        "    mae = np.mean(np.abs(pred_all - target_all))\n",
        "    return mae\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0rqwI5h4YH6j"
      },
      "outputs": [],
      "source": [
        "def rmse(true, pred):\n",
        "    \"\"\"Calculate the Root Mean Squared Error (RMSE).\"\"\"\n",
        "    return np.sqrt(np.mean((true - pred)**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QuupsoIvdGj2"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_on_full_train(model, loader) -> float:\n",
        "    model.eval()\n",
        "    pred_list, target_list = [], []\n",
        "\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch, task.entity_table)\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.cpu())\n",
        "        target_list.append(batch[task.entity_table].y.cpu())\n",
        "\n",
        "    pred_all = torch.cat(pred_list, dim=0).numpy()\n",
        "    target_all = torch.cat(target_list, dim=0).numpy()\n",
        "\n",
        "    mae = np.mean(np.abs(pred_all - target_all))\n",
        "    return mae\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cPY4bzTVpzsf"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0, verbose=False, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Quanto aspettare senza miglioramenti prima di fermare.\n",
        "            delta (float): Miglioramento minimo richiesto per considerare un miglioramento.\n",
        "            verbose (bool): Se stampare informazioni.\n",
        "            path (str): Dove salvare il modello migliore.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "        self.verbose = verbose\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss  # Perché vogliamo MINIMIZZARE la loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} / {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Salva il modello migliore'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss migliorata ({self.val_loss_min:.6f} --> {val_loss:.6f}). Salvo modello...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6q-HPJfr7c_"
      },
      "source": [
        "# Dataset and task creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DWB-Kf6nl2y",
        "outputId": "b1870573-66c9-44b8-ae41-027698ac5508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'rel-f1/db.zip' from 'https://relbench.stanford.edu/download/rel-f1/db.zip' to '/root/.cache/relbench'.\n",
            "100%|████████████████████████████████████████| 704k/704k [00:00<00:00, 618MB/s]\n",
            "Unzipping contents of '/root/.cache/relbench/rel-f1/db.zip' to '/root/.cache/relbench/rel-f1/.'\n",
            "Downloading file 'rel-f1/tasks/driver-position.zip' from 'https://relbench.stanford.edu/download/rel-f1/tasks/driver-position.zip' to '/root/.cache/relbench'.\n",
            "100%|█████████████████████████████████████| 36.5k/36.5k [00:00<00:00, 44.9MB/s]\n",
            "Unzipping contents of '/root/.cache/relbench/rel-f1/tasks/driver-position.zip' to '/root/.cache/relbench/rel-f1/tasks/.'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Loading Database object from /root/.cache/relbench/rel-f1/db...\n",
            "Done in 0.05 seconds.\n"
          ]
        }
      ],
      "source": [
        "dataset = get_dataset(\"rel-f1\", download=True)\n",
        "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
        "\n",
        "train_table = task.get_table(\"train\") #date  driverId  qualifying\n",
        "val_table = task.get_table(\"val\") #date  driverId  qualifying\n",
        "test_table = task.get_table(\"test\") # date  driverId\n",
        "\n",
        "out_channels = 1\n",
        "loss_fn = L1Loss()\n",
        "# this is the mae loss and is used when have regressions tasks.\n",
        "tune_metric = \"mae\"\n",
        "higher_is_better = False\n",
        "\n",
        "seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "root_dir = \"./data\"\n",
        "\n",
        "db = dataset.get_db() #get all tables\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "entity_table = task.entity_table\n",
        "#this is used to get the stype of the columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(db.table_dict.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuMISXZv8LVS",
        "outputId": "fe806293-ff52-48d9-c267-a37759520208"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['standings',\n",
              " 'constructor_results',\n",
              " 'constructor_standings',\n",
              " 'constructors',\n",
              " 'qualifying',\n",
              " 'results',\n",
              " 'circuits',\n",
              " 'races',\n",
              " 'drivers']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gvkjcjPr7dB"
      },
      "source": [
        "# Embedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QQHYmgIxkX1j"
      },
      "outputs": [],
      "source": [
        "class LightweightGloveEmbedder:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device\n",
        "        self.embeddings = defaultdict(lambda: np.zeros(300))\n",
        "        self._load_embeddings()\n",
        "\n",
        "    def _load_embeddings(self):\n",
        "      try:\n",
        "          path = \"glove.6B.300d.txt\"\n",
        "          with open(path, encoding=\"utf-8\") as f:\n",
        "              for line in f:\n",
        "                  parts = line.strip().split()\n",
        "                  word = parts[0]\n",
        "                  vector = np.array(parts[1:], dtype=np.float32)\n",
        "                  self.embeddings[word] = vector\n",
        "          #print(f\"Loaded {len(self.embeddings)} GloVe embeddings.\")\n",
        "      except Exception as e:\n",
        "          print(f\"Failed to load GloVe: {e}\")\n",
        "\n",
        "    def __call__(self, sentences):\n",
        "        results = []\n",
        "        for text in sentences:\n",
        "            words = text.lower().split()\n",
        "            vectors = [self.embeddings[w] for w in words if w in self.embeddings]\n",
        "            if vectors:\n",
        "                avg_vector = np.mean(vectors, axis=0)\n",
        "            else:\n",
        "                #print(\"non trovato\")\n",
        "                #print(f\"Numero parole in embedding: {len(self.embeddings)}\")\n",
        "\n",
        "                avg_vector = np.zeros(300)\n",
        "            results.append(avg_vector)\n",
        "\n",
        "        tensor = torch.tensor(np.array(results), dtype=torch.float32)\n",
        "        return tensor.to(self.device) if self.device else tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L-BBpUrakdwY"
      },
      "outputs": [],
      "source": [
        "text_embedder_cfg = TextEmbedderConfig(\n",
        "    text_embedder=LightweightGloveEmbedder(device=device), batch_size=256\n",
        ")\n",
        "\n",
        "# data, col_stats_dict = make_pkey_fkey_graph(\n",
        "#     db,\n",
        "#     col_to_stype_dict=col_to_stype_dict,\n",
        "#     text_embedder_cfg=text_embedder_cfg,\n",
        "#     cache_dir=os.path.join(\n",
        "#         root_dir, f\"rel-f1_materialized_cache\"\n",
        "#     ),\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xMIwSVTXXnr"
      },
      "source": [
        "# Graph Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LDbdc2Iz1Odp"
      },
      "outputs": [],
      "source": [
        "# qui i parametri di train_table, val_table, test_table, task e data sono\n",
        "#parametri globali\n",
        "\n",
        "def loader_dict_fn(batch_size, num_neighbours, data):\n",
        "    loader_dict = {}\n",
        "\n",
        "    for split, table in [\n",
        "        (\"train\", train_table),\n",
        "        (\"val\", val_table),\n",
        "        (\"test\", test_table),\n",
        "    ]:\n",
        "        table_input = get_node_train_table_input(\n",
        "            table=table,\n",
        "            task=task,\n",
        "        )\n",
        "\n",
        "        loader_dict[split] = NeighborLoader(\n",
        "            data,\n",
        "            num_neighbors=[num_neighbours for _ in range(2)],\n",
        "            time_attr=\"time\",\n",
        "            input_nodes=table_input.nodes,\n",
        "            input_time=table_input.time,\n",
        "            transform=table_input.transform,\n",
        "            batch_size=batch_size,\n",
        "            temporal_strategy=\"uniform\",\n",
        "            shuffle=split == \"train\",\n",
        "            num_workers=0,\n",
        "            persistent_workers=False,\n",
        "        )\n",
        "\n",
        "    return loader_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr7qtFXgr7dE"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u3m3jEqClQnw"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData,\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "\n",
        "        self.gnn = HeteroGraphSAGE(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            aggr=aggr,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1, ###################################################\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H1f8MgdYMFQ"
      },
      "source": [
        "# Training functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04u3lZVg4I3n"
      },
      "source": [
        "Ora necessito di modificare la funzione di train per prendere anche il valore del loader_dict: utile per tuning dei parametri (vedi il codice della funzione di tuning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SAHRIr15lVs6"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, loader_dict) -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9TjoM9pzkAy",
        "outputId": "5882bf39-0d46-4fb4-8150-ef68d36b3bbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "position\n"
          ]
        }
      ],
      "source": [
        "print(task.target_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scheduler tuning"
      ],
      "metadata": {
        "id": "7qI7pTh6gjoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import copy\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR, ReduceLROnPlateau, OneCycleLR\n",
        "\n",
        "\n",
        "def get_scheduler(name, optimizer, loader_len, epochs):\n",
        "    if name == \"cosine\":\n",
        "        return CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    elif name == \"linear_warmup\":\n",
        "        def lr_lambda(epoch):\n",
        "            warmup_epochs = 5\n",
        "            if epoch < warmup_epochs:\n",
        "                return (epoch + 1) / warmup_epochs\n",
        "            return max(0.1, 1 - (epoch - warmup_epochs) / (epochs - warmup_epochs))\n",
        "        return LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "    elif name == \"plateau\":\n",
        "        return ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=10, verbose=True)\n",
        "\n",
        "    elif name == \"onecycle\":\n",
        "        return OneCycleLR(optimizer, max_lr=0.001, steps_per_epoch=loader_len, epochs=epochs)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown scheduler: {name}\")\n",
        "\n",
        "\n",
        "def evaluate_scheduler(scheduler_name, model_init_fn, loader_dict_fn, train_fn, test_fn,\n",
        "                        evaluate_fn, task, val_table, epochs, device):\n",
        "    model = model_init_fn().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0)\n",
        "    loader_dict = loader_dict_fn()\n",
        "    scheduler = get_scheduler(scheduler_name, optimizer, len(loader_dict[\"train\"]), epochs)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_fn(model, optimizer, loader_dict)\n",
        "        if scheduler_name == \"plateau\":\n",
        "            val_pred = test_fn(model, loader_dict[\"val\"])\n",
        "            val_mae = evaluate_fn(val_pred, val_table, task.metrics)[\"mae\"]\n",
        "            scheduler.step(val_mae)\n",
        "        elif scheduler_name == \"onecycle\":\n",
        "            # Step per batch\n",
        "            for _ in loader_dict[\"train\"]:\n",
        "                scheduler.step()\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "    val_pred = test_fn(model, loader_dict[\"val\"])\n",
        "    val_mae = evaluate_fn(val_pred, val_table, task.metrics)[\"mae\"]\n",
        "    return val_mae\n",
        "\n",
        "\n",
        "def compare_schedulers(model_init_fn, loader_dict_fn, train_fn, test_fn,\n",
        "                        evaluate_fn, task, val_table, epochs, device):\n",
        "    schedulers = [\"cosine\", \"linear_warmup\", \"plateau\", \"onecycle\"]\n",
        "    results = {}\n",
        "\n",
        "    for name in schedulers:\n",
        "        print(f\"Testing scheduler: {name}\")\n",
        "        val_mae = evaluate_scheduler(name, model_init_fn, loader_dict_fn, train_fn, test_fn,\n",
        "                                     evaluate_fn, task, val_table, epochs, device)\n",
        "        results[name] = val_mae\n",
        "        print(f\"{name} val_mae: {val_mae:.4f}\")\n",
        "\n",
        "    best_scheduler = min(results, key=results.get)\n",
        "    print(f\"\\nBest scheduler: {best_scheduler} (val_mae: {results[best_scheduler]:.4f})\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "LuDBrCoBglq9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compare_schedulers(\n",
        "#     model_init_fn=lambda: Model(\n",
        "#             data=data,\n",
        "#             col_stats_dict=col_stats_dict,\n",
        "#             num_layers=2,\n",
        "#             channels=128,\n",
        "#             out_channels=1,\n",
        "#             aggr=\"max\",\n",
        "#             norm=\"batch_norm\",\n",
        "#     ).to(device),\n",
        "#     loader_dict_fn=lambda: loader_dict_fn(batch_size=512, num_neighbours=256, data=data),\n",
        "#     train_fn=train,\n",
        "#     test_fn=test,\n",
        "#     evaluate_fn=evaluate_performance,\n",
        "#     task=task,\n",
        "#     val_table=val_table,\n",
        "#     epochs=50,\n",
        "#     device=device\n",
        "# )\n"
      ],
      "metadata": {
        "id": "s35xKwnGgpaP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il migliore scheduler è quindi cosine:\n",
        "\n",
        "Best scheduler: cosine (val_mae: 2.9038)\n",
        "{'cosine': 2.9038224850325243,\n",
        " 'linear_warmup': 2.915358568750865,\n",
        " 'plateau': 3.30474050643847,\n",
        " 'onecycle': 3.1991489658215557}"
      ],
      "metadata": {
        "id": "WCedFRvKgsc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation on tables"
      ],
      "metadata": {
        "id": "r2YI11G3UYeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_graph_excluding_tables(dataset, tables_to_remove, root_dir, text_embedder_cfg):\n",
        "    import copy\n",
        "    from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "\n",
        "    # 1. Deepcopy del db originale\n",
        "    original_db = dataset.get_db()\n",
        "    db = copy.deepcopy(original_db)\n",
        "\n",
        "    # 2. Rimuovi tutte le tabelle\n",
        "    for table_to_remove in tables_to_remove:\n",
        "        if table_to_remove in db.table_dict:\n",
        "            del db.table_dict[table_to_remove]\n",
        "\n",
        "    # 3. Rimuovi fkey che puntano a tabelle escluse\n",
        "    for table in db.table_dict.values():\n",
        "        table.fkey_col_to_pkey_table = {\n",
        "            col: tgt for col, tgt in table.fkey_col_to_pkey_table.items()\n",
        "            if tgt not in tables_to_remove\n",
        "        }\n",
        "        # Rimuoviamo anche le colonne fkey nei df\n",
        "        table.df = table.df.drop(\n",
        "            columns=[\n",
        "                col for col, tgt in table.fkey_col_to_pkey_table.items()\n",
        "                if tgt not in db.table_dict\n",
        "            ],\n",
        "            errors=\"ignore\"\n",
        "        )\n",
        "\n",
        "    # 4. Filtra anche lo stype\n",
        "    full_stype = get_stype_proposal(original_db)\n",
        "    filtered_stype = {\n",
        "        tab: stype for tab, stype in full_stype.items()\n",
        "        if tab not in tables_to_remove\n",
        "    }\n",
        "\n",
        "    # 5. Costruzione del grafo UNA sola volta\n",
        "    cache_name = \"_\".join(sorted(tables_to_remove))\n",
        "    data, col_stats_dict = make_pkey_fkey_graph(\n",
        "        db,\n",
        "        col_to_stype_dict=filtered_stype,\n",
        "        text_embedder_cfg=text_embedder_cfg,\n",
        "        cache_dir=os.path.join(root_dir, f\"ablation_cache_{cache_name}\")\n",
        "    )\n",
        "\n",
        "    all_tables = list(db.table_dict.keys())\n",
        "    print(f\"Tabelle rimanenti nel grafo: {all_tables}\")\n",
        "\n",
        "    return data, col_stats_dict, db\n"
      ],
      "metadata": {
        "id": "f0YZY5xjS5In"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation on features"
      ],
      "metadata": {
        "id": "yGGJr5wfYVZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "QXRiIIRdcCae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import os\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "from tqdm import tqdm\n",
        "\n",
        "def run_feature_ablation(dataset, task, root_dir, text_embedder_cfg):\n",
        "    db_original = dataset.get_db()\n",
        "    results = []\n",
        "\n",
        "    for table_name, table in db_original.table_dict.items():\n",
        "        df = table.df\n",
        "        pkey = table.pkey_col\n",
        "        fkeys = set(table.fkey_col_to_pkey_table.keys())\n",
        "        y_col = task.target_col if table_name == task.entity_table else None\n",
        "\n",
        "        # Candidati: tutte le colonne meno chiavi e target\n",
        "        feature_cols = [col for col in df.columns\n",
        "                        if col not in fkeys and col != pkey and col != y_col]\n",
        "\n",
        "        for feature in tqdm(feature_cols, desc=f\"{table_name}\"):\n",
        "            # 1. Copia il db\n",
        "            db = copy.deepcopy(db_original)\n",
        "\n",
        "            # 2. Rimuovi la colonna dal df e dallo stype\n",
        "            db.table_dict[table_name].df = db.table_dict[table_name].df.drop(columns=[feature])\n",
        "\n",
        "            # 3. Ricostruisci stype\n",
        "            stype_dict = get_stype_proposal(db)\n",
        "\n",
        "            # 4. Costruzione grafo\n",
        "            try:\n",
        "                data, col_stats_dict = make_pkey_fkey_graph(\n",
        "                    db,\n",
        "                    col_to_stype_dict=stype_dict,\n",
        "                    text_embedder_cfg=text_embedder_cfg,\n",
        "                    cache_dir=os.path.join(root_dir, f\"ablation_cache_{table_name}_{feature}\")\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping {table_name}.{feature} due to error: {e}\")\n",
        "                continue\n",
        "\n",
        "            # 5. Build model and loader\n",
        "            model = Model(\n",
        "                data=data,\n",
        "                col_stats_dict=col_stats_dict,\n",
        "                num_layers=2,\n",
        "                channels=128,\n",
        "                out_channels=1,\n",
        "                aggr=\"max\",\n",
        "                norm=\"batch_norm\",\n",
        "            ).to(device)\n",
        "\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0)\n",
        "            loader_dict = loader_dict_fn(batch_size=512, num_neighbours=256, data=data)\n",
        "\n",
        "            # 6. Training breve\n",
        "            for _ in range(15):\n",
        "                train(model, optimizer, loader_dict)\n",
        "\n",
        "            val_pred = test(model, loader_dict[\"val\"])\n",
        "            val_mae = evaluate_performance(val_pred, val_table, task.metrics)[\"mae\"]\n",
        "\n",
        "            results.append({\n",
        "                \"table\": table_name,\n",
        "                \"feature\": feature,\n",
        "                \"val_mae\": val_mae,\n",
        "            })\n",
        "\n",
        "    return sorted(results, key=lambda x: x[\"val_mae\"], reverse=True)\n"
      ],
      "metadata": {
        "id": "2ysf3lcpYkIv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run_feature_ablation(dataset, task, \"root\", text_embedder_cfg)"
      ],
      "metadata": {
        "id": "il6VCX6Ja42f"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[{'table': 'results',\n",
        "  'feature': 'positionOrder',\n",
        "  'val_mae': 3.950804795244175},\n",
        "\n",
        "\n",
        " {'table': 'standings', 'feature': 'position', 'val_mae': 3.8903072947092507},\n",
        "\n",
        "\n",
        " {'table': 'races', 'feature': 'round', 'val_mae': 3.8874379688688494},\n",
        "\n",
        "\n",
        " {'table': 'circuits', 'feature': 'country', 'val_mae': 3.8866149727790136},\n",
        "\n",
        "\n",
        " {'table': 'constructor_standings',\n",
        "  'feature': 'points',\n",
        "  'val_mae': 3.8830483684399644},\n",
        "\n",
        "\n",
        " {'table': 'results', 'feature': 'position', 'val_mae': 3.881930207282444},\n",
        "\n",
        "\n",
        " {'table': 'circuits', 'feature': 'name', 'val_mae': 3.8806671545198146},\n",
        "\n",
        "\n",
        " {'table': 'circuits', 'feature': 'circuitRef', 'val_mae': 3.8796486551951155},\n",
        "\n",
        "\n",
        " {'table': 'results', 'feature': 'rank', 'val_mae': 3.8729131191511033},\n",
        "\n",
        "\n",
        " {'table': 'drivers', 'feature': 'surname', 'val_mae': 3.8721600948529957},\n",
        "\n",
        "\n",
        " {'table': 'drivers', 'feature': 'code', 'val_mae': 3.8716865850434594},\n",
        "\n",
        "\n",
        " {'table': 'constructors',\n",
        "  'feature': 'nationality',\n",
        "  'val_mae': 3.8713674863816583},\n",
        "\n",
        "\n",
        " {'table': 'circuits', 'feature': 'alt', 'val_mae': 3.870047071733392},\n",
        "\n",
        "\n",
        " {'table': 'results', 'feature': 'grid', 'val_mae': 3.8692150931399745},\n",
        "\n",
        "\n",
        " {'table': 'standings', 'feature': 'points', 'val_mae': 3.8686533158989693},\n",
        "\n",
        "\n",
        " {'table': 'drivers', 'feature': 'dob', 'val_mae': 3.8663228321011736},\n",
        "\n",
        "\n",
        " {'table': 'standings', 'feature': 'wins', 'val_mae': 3.866027179684891},\n",
        "\n",
        "\n",
        " {'table': 'constructor_standings',\n",
        "  'feature': 'position',\n",
        "  'val_mae': 3.8660021299669247},\n",
        "\n",
        "\n",
        " {'table': 'results',\n",
        "  'feature': 'milliseconds',\n",
        "  'val_mae': 3.8608299076995136},\n",
        "\n",
        "\n",
        "\n",
        " {'table': 'results', 'feature': 'statusId', 'val_mae': 3.8595401444113406},\n",
        "\n",
        "\n",
        " {'table': 'races', 'feature': 'year', 'val_mae': 3.8587325821738285},\n",
        "\n",
        "\n",
        " {'table': 'qualifying', 'feature': 'number', 'val_mae': 3.858693720423228},\n",
        "\n",
        "\n",
        " {'table': 'results', 'feature': 'number', 'val_mae': 3.8582406295643863},\n",
        "\n",
        "\n",
        " {'table': 'results', 'feature': 'points', 'val_mae': 3.857474676194634},\n",
        "\n",
        "\n",
        " {'table': 'qualifying', 'feature': 'position', 'val_mae': 3.857085906559416},\n",
        "\n",
        "\n",
        " {'table': 'circuits', 'feature': 'location', 'val_mae': 3.8563255510094487},\n",
        "\n",
        "\n",
        " {'table': 'constructor_results',\n",
        "  'feature': 'points',\n",
        "  'val_mae': 3.8561439144667102},\n",
        "\n",
        "\n",
        " {'table': 'races', 'feature': 'time', 'val_mae': 3.8559820535745155},\n",
        "\n",
        "\n",
        " {'table': 'results', 'feature': 'fastestLap', 'val_mae': 3.855821519799446},\n",
        "\n",
        "\n",
        " {'table': 'drivers', 'feature': 'nationality', 'val_mae': 3.8555740881380274},\n",
        "\n",
        "\n",
        " {'table': 'results', 'feature': 'laps', 'val_mae': 3.8554142874881436},\n",
        "\n",
        "\n",
        " {'table': 'drivers', 'feature': 'driverRef', 'val_mae': 3.8553647816619163},\n",
        "\n",
        "\n",
        " {'table': 'constructor_standings',\n",
        "  'feature': 'wins',\n",
        "  'val_mae': 3.85485139335882},\n",
        "\n",
        "\n",
        " {'table': 'drivers', 'feature': 'forename', 'val_mae': 3.854089958761721},\n",
        "\n",
        "\n",
        " {'table': 'circuits', 'feature': 'lat', 'val_mae': 3.8531440858452335},\n",
        "\n",
        "\n",
        " {'table': 'constructors', 'feature': 'name', 'val_mae': 3.8531423841385974},\n",
        "\n",
        "\n",
        " {'table': 'circuits', 'feature': 'lng', 'val_mae': 3.852716157463446},\n",
        "\n",
        "\n",
        " {'table': 'races', 'feature': 'name', 'val_mae': 3.851620068419513},\n",
        "\n",
        "\n",
        " {'table': 'constructors',\n",
        "  'feature': 'constructorRef',\n",
        "  'val_mae': 3.8499111845721066}]"
      ],
      "metadata": {
        "id": "eQPLI0RPbKP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main results"
      ],
      "metadata": {
        "id": "CD4Xg3PJcLQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features essenziali:\n",
        "\n",
        "\n",
        "| Tabella     | Feature         | MAE  | ΔMAE (≈) | Impatto        |\n",
        "| ----------- | --------------- | ---- | -------- | -------------- |\n",
        "| `results`   | `positionOrder` | 3.95 | +0.08    |  **Critica** |\n",
        "| `standings` | `position`      | 3.89 | +0.02    |  Utile       |\n",
        "| `races`     | `round`         | 3.88 | +0.01    |  Utile       |\n"
      ],
      "metadata": {
        "id": "HVrDBwQzWfM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Features meno importanti:\n",
        "\n",
        "\n",
        "| Tabella        | Feature          | MAE    | ΔMAE (≈) | Impatto         |\n",
        "| -------------- | ---------------- | ------ | -------- | --------------- |\n",
        "| `constructors` | `constructorRef` | 3.8499 | −0.02    | Forse rumore |\n",
        "| `races`        | `name`           | 3.8516 | −0.02    | Inutile      |\n",
        "| `circuits`     | `lng`            | 3.8527 | −0.02    | Inutile      |\n"
      ],
      "metadata": {
        "id": "1MxvySwsWnfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "results.positionOrder è la feature più importante del dataset.\n",
        "\n",
        "Feature come position, round, points... contribuiscono sensibilmente.\n",
        "\n",
        "Alcune feature testuali o descrittive (name, location, constructorRef) non aiutano, e anzi potrebbero essere rumorose.\n",
        "\n"
      ],
      "metadata": {
        "id": "mVLg5CWQWzks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for removing features"
      ],
      "metadata": {
        "id": "dylFaSbicGG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import os\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "\n",
        "def get_graph_without_features(db, features_to_remove, root_dir, text_embedder_cfg):\n",
        "    \"\"\"\n",
        "    Rimuove un insieme di feature specificate da diverse tabelle e restituisce il grafo aggiornato.\n",
        "\n",
        "    :param dataset: Il dataset originale (oggetto relbench)\n",
        "    :param features_to_remove: Lista di tuple (table_name, feature_name)\n",
        "    :param root_dir: Cartella cache\n",
        "    :param text_embedder_cfg: Configurazione dell'embedding testuale\n",
        "    :return: (data, col_stats_dict)\n",
        "     \"\"\"\n",
        "    # db_original = dataset.get_db()\n",
        "    # db = copy.deepcopy(db_original)\n",
        "\n",
        "    # Rimuove le feature indicate\n",
        "    for table_name, feature in features_to_remove:\n",
        "        if table_name in db.table_dict:\n",
        "            table = db.table_dict[table_name]\n",
        "            if feature in table.df.columns:\n",
        "                table.df = table.df.drop(columns=[feature])\n",
        "        else:\n",
        "          print(f\"feature {feature}  di tabella {table_name} non presente\")\n",
        "\n",
        "    # Ricostruisce lo stype_dict aggiornato\n",
        "    stype_dict = get_stype_proposal(db)\n",
        "\n",
        "    # Costruzione grafo aggiornato\n",
        "    cache_name = \"__\".join([f\"{t}_{f}\" for t, f in features_to_remove])\n",
        "    data, col_stats_dict = make_pkey_fkey_graph(\n",
        "        db,\n",
        "        col_to_stype_dict=stype_dict,\n",
        "        text_embedder_cfg=text_embedder_cfg,\n",
        "        cache_dir=os.path.join(root_dir, f\"feature_ablation_cache_{cache_name}\")\n",
        "    )\n",
        "\n",
        "    return data, col_stats_dict\n"
      ],
      "metadata": {
        "id": "KTM3rT5mcI51"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "i3lw7KeHYSkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tables ablation"
      ],
      "metadata": {
        "id": "4b673I0UdQ2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Testing without table: circuits and constructor_result\")\n",
        "tables_to_remove = [\"circuits\",\"constructor_results\"]\n",
        "\n",
        "data, col_stats_dict, db = build_graph_excluding_tables(\n",
        "        dataset, tables_to_remove=tables_to_remove,\n",
        "        root_dir=root_dir,\n",
        "        text_embedder_cfg=text_embedder_cfg\n",
        ")\n",
        "\n",
        "loader_dict = loader_dict_fn(batch_size=512, num_neighbours=256, data=data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtLRzIE5dS4k",
        "outputId": "18a8b023-da0d-4ea1-807c-312e3752b759"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing without table: circuits and constructor_result\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 250.57it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 243.83it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/data/stats.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  ser = pd.to_datetime(ser, format=time_format)\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 219.34it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/data/mapper.py:291: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  ser = pd.to_datetime(ser, format=self.format, errors='coerce')\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 724.53it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 290.75it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 247.69it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 245.99it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 296.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabelle rimanenti nel grafo: ['standings', 'constructor_standings', 'constructors', 'qualifying', 'results', 'races', 'drivers']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features ablation"
      ],
      "metadata": {
        "id": "b6C_0x8jdTeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_to_remove = [\n",
        "    (\"constructors\", \"constructorRef\"),\n",
        "    (\"constructors\", \"name\"),\n",
        "    (\"races\", \"name\"),\n",
        "    (\"circuits\", \"lat\"),#vediamo se non presente\n",
        "    (\"circuits\", \"lng\"),#idem\n",
        "    (\"drivers\", \"forename\"),\n",
        "    (\"drivers\", \"driverRef\"),\n",
        "    (\"drivers\", \"nationality\"),\n",
        "    (\"constructor_standings\", \"wins\"),\n",
        "    (\"results\", \"laps\"),\n",
        "    (\"results\", \"points\")\n",
        "]\n",
        "\n",
        "data, col_stats_dict = get_graph_without_features(db, features_to_remove, root_dir, text_embedder_cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IulOpPcmdW5D",
        "outputId": "a2cf279c-3190-41fb-cba2-a9e47a2619e5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature lat  di tabella circuits non presente\n",
            "feature lng  di tabella circuits non presente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 230.33it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/data/stats.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  ser = pd.to_datetime(ser, format=time_format)\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/data/mapper.py:291: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  ser = pd.to_datetime(ser, format=self.format, errors='coerce')\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 480.68it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 215.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "J0UNvMVAdXgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader_dict = loader_dict_fn(batch_size=512, num_neighbours=256, data=data)\n",
        "\n",
        "model = Model(\n",
        "        data=data,\n",
        "        col_stats_dict=col_stats_dict,\n",
        "        num_layers=2,\n",
        "        channels=128,\n",
        "        out_channels=1,\n",
        "        aggr=\"max\",\n",
        "        norm=\"batch_norm\",\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0)\n",
        "\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#         optimizer,\n",
        "#         mode=\"min\",\n",
        "#         factor=0.5,\n",
        "#         patience=10,\n",
        "#         verbose=True\n",
        "# )\n",
        "epochs = 600\n",
        "\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    patience=30,\n",
        "    delta=0.0,\n",
        "    verbose=True,\n",
        "    path=\"best_basic_model.pt\"\n",
        ")\n",
        "\n",
        "\n",
        "state_dict = None\n",
        "test_table = task.get_table(\"test\", mask_input_cols=False)\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "best_test_metric = -math.inf if higher_is_better else math.inf\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(model, optimizer, loader_dict=loader_dict)\n",
        "\n",
        "    train_pred = test(model, loader_dict[\"train\"])\n",
        "    train_metrics = evaluate_performance(train_pred, train_table, task.metrics)\n",
        "    train_mae_preciso = evaluate_on_full_train(model, loader_dict[\"train\"])\n",
        "\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    val_metrics = evaluate_performance(val_pred, val_table, task.metrics)\n",
        "\n",
        "    test_pred = test(model, loader_dict[\"test\"])\n",
        "    test_metrics = evaluate_performance(test_pred, test_table, task.metrics)\n",
        "\n",
        "    scheduler.step(val_metrics[tune_metric])\n",
        "\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    #test:\n",
        "    if (higher_is_better and test_metrics[tune_metric] > best_test_metric) or (\n",
        "            not higher_is_better and test_metrics[tune_metric] < best_test_metric\n",
        "    ):\n",
        "        best_test_metric = test_metrics[tune_metric]\n",
        "        state_dict_test = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "    print(f\"Epoch: {epoch:02d}, Train mae: {train_mae_preciso:.2f}, Validation MAE: {val_metrics[tune_metric]:.2f}, Test MAE: {test_metrics[tune_metric]:.2f}, LR: {current_lr:.6f}\")\n",
        "\n",
        "    early_stopping(val_metrics[tune_metric], model)\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "        print(f\"Early stopping triggered at epoch {epoch}\")\n",
        "        break\n",
        "print(f\"best validation results: {best_val_metric}\")\n",
        "print(f\"best test results: {best_test_metric}\")"
      ],
      "metadata": {
        "id": "tAycUfHOYUUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5829774b-8479-4acc-ad83-6b30eb66ae17"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.43it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Train mae: 10.52, Validation MAE: 7.70, Test MAE: 8.56, LR: 0.000500\n",
            "Validation loss migliorata (inf --> 7.699859). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  6.14it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02, Train mae: 10.00, Validation MAE: 7.17, Test MAE: 8.03, LR: 0.000500\n",
            "Validation loss migliorata (7.699859 --> 7.165066). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.98it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03, Train mae: 9.58, Validation MAE: 6.75, Test MAE: 7.59, LR: 0.000500\n",
            "Validation loss migliorata (7.165066 --> 6.745498). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.95it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 04, Train mae: 9.16, Validation MAE: 6.35, Test MAE: 7.18, LR: 0.000500\n",
            "Validation loss migliorata (6.745498 --> 6.348452). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.96it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05, Train mae: 8.76, Validation MAE: 5.97, Test MAE: 6.80, LR: 0.000500\n",
            "Validation loss migliorata (6.348452 --> 5.970862). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.57it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 06, Train mae: 8.37, Validation MAE: 5.61, Test MAE: 6.45, LR: 0.000500\n",
            "Validation loss migliorata (5.970862 --> 5.608460). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.97it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 07, Train mae: 7.99, Validation MAE: 5.29, Test MAE: 6.12, LR: 0.000500\n",
            "Validation loss migliorata (5.608460 --> 5.285204). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.19it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 08, Train mae: 7.64, Validation MAE: 4.99, Test MAE: 5.81, LR: 0.000500\n",
            "Validation loss migliorata (5.285204 --> 4.989032). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.98it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 09, Train mae: 7.31, Validation MAE: 4.73, Test MAE: 5.52, LR: 0.000500\n",
            "Validation loss migliorata (4.989032 --> 4.725163). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.23it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Train mae: 7.01, Validation MAE: 4.50, Test MAE: 5.25, LR: 0.000500\n",
            "Validation loss migliorata (4.725163 --> 4.503823). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.84it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11, Train mae: 6.74, Validation MAE: 4.31, Test MAE: 5.03, LR: 0.000500\n",
            "Validation loss migliorata (4.503823 --> 4.313928). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.38it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12, Train mae: 6.50, Validation MAE: 4.16, Test MAE: 4.83, LR: 0.000500\n",
            "Validation loss migliorata (4.313928 --> 4.163872). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.61it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13, Train mae: 6.31, Validation MAE: 4.05, Test MAE: 4.68, LR: 0.000500\n",
            "Validation loss migliorata (4.163872 --> 4.052688). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.49it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14, Train mae: 6.13, Validation MAE: 3.96, Test MAE: 4.55, LR: 0.000500\n",
            "Validation loss migliorata (4.052688 --> 3.963899). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.63it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15, Train mae: 5.99, Validation MAE: 3.90, Test MAE: 4.46, LR: 0.000500\n",
            "Validation loss migliorata (3.963899 --> 3.898593). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.55it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16, Train mae: 5.87, Validation MAE: 3.86, Test MAE: 4.39, LR: 0.000500\n",
            "Validation loss migliorata (3.898593 --> 3.863406). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.76it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17, Train mae: 5.78, Validation MAE: 3.86, Test MAE: 4.35, LR: 0.000500\n",
            "Validation loss migliorata (3.863406 --> 3.856908). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.77it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18, Train mae: 5.71, Validation MAE: 3.86, Test MAE: 4.33, LR: 0.000500\n",
            "EarlyStopping counter: 1 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.76it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19, Train mae: 5.66, Validation MAE: 3.88, Test MAE: 4.32, LR: 0.000500\n",
            "EarlyStopping counter: 2 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.77it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20, Train mae: 5.62, Validation MAE: 3.90, Test MAE: 4.31, LR: 0.000500\n",
            "EarlyStopping counter: 3 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.63it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21, Train mae: 5.59, Validation MAE: 3.89, Test MAE: 4.29, LR: 0.000500\n",
            "EarlyStopping counter: 4 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.71it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22, Train mae: 5.55, Validation MAE: 3.77, Test MAE: 4.20, LR: 0.000500\n",
            "Validation loss migliorata (3.856908 --> 3.772424). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.29it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23, Train mae: 5.45, Validation MAE: 3.43, Test MAE: 3.96, LR: 0.000500\n",
            "Validation loss migliorata (3.772424 --> 3.430688). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.75it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24, Train mae: 5.28, Validation MAE: 3.36, Test MAE: 3.88, LR: 0.000500\n",
            "Validation loss migliorata (3.430688 --> 3.359099). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.10it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25, Train mae: 5.13, Validation MAE: 3.14, Test MAE: 3.84, LR: 0.000500\n",
            "Validation loss migliorata (3.359099 --> 3.144816). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.78it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26, Train mae: 4.97, Validation MAE: 3.04, Test MAE: 3.90, LR: 0.000500\n",
            "Validation loss migliorata (3.144816 --> 3.036825). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:03<00:00,  4.94it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27, Train mae: 4.89, Validation MAE: 2.96, Test MAE: 4.01, LR: 0.000500\n",
            "Validation loss migliorata (3.036825 --> 2.961598). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.76it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28, Train mae: 4.81, Validation MAE: 2.85, Test MAE: 4.12, LR: 0.000500\n",
            "Validation loss migliorata (2.961598 --> 2.847815). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.14it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29, Train mae: 4.74, Validation MAE: 2.94, Test MAE: 4.01, LR: 0.000500\n",
            "EarlyStopping counter: 1 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.93it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30, Train mae: 4.68, Validation MAE: 2.83, Test MAE: 4.16, LR: 0.000500\n",
            "Validation loss migliorata (2.847815 --> 2.826951). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.52it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31, Train mae: 4.67, Validation MAE: 2.98, Test MAE: 4.03, LR: 0.000500\n",
            "EarlyStopping counter: 1 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.88it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32, Train mae: 4.64, Validation MAE: 2.90, Test MAE: 4.11, LR: 0.000500\n",
            "EarlyStopping counter: 2 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.82it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33, Train mae: 4.65, Validation MAE: 2.84, Test MAE: 4.26, LR: 0.000500\n",
            "EarlyStopping counter: 3 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.90it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34, Train mae: 4.55, Validation MAE: 2.87, Test MAE: 4.17, LR: 0.000500\n",
            "EarlyStopping counter: 4 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.84it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 35, Train mae: 4.46, Validation MAE: 2.88, Test MAE: 4.20, LR: 0.000500\n",
            "EarlyStopping counter: 5 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.50it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 36, Train mae: 4.42, Validation MAE: 2.95, Test MAE: 4.23, LR: 0.000500\n",
            "EarlyStopping counter: 6 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.65it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 37, Train mae: 4.40, Validation MAE: 2.88, Test MAE: 4.31, LR: 0.000500\n",
            "EarlyStopping counter: 7 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.24it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 38, Train mae: 4.36, Validation MAE: 3.15, Test MAE: 4.24, LR: 0.000500\n",
            "EarlyStopping counter: 8 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.78it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 39, Train mae: 4.34, Validation MAE: 2.98, Test MAE: 4.28, LR: 0.000500\n",
            "EarlyStopping counter: 9 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:03<00:00,  4.98it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 40, Train mae: 4.24, Validation MAE: 3.02, Test MAE: 4.46, LR: 0.000500\n",
            "EarlyStopping counter: 10 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.67it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 41, Train mae: 4.19, Validation MAE: 3.02, Test MAE: 4.55, LR: 0.000500\n",
            "EarlyStopping counter: 11 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.02it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 42, Train mae: 4.12, Validation MAE: 3.06, Test MAE: 4.56, LR: 0.000500\n",
            "EarlyStopping counter: 12 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.70it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 43, Train mae: 4.09, Validation MAE: 3.02, Test MAE: 4.63, LR: 0.000500\n",
            "EarlyStopping counter: 13 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.29it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 44, Train mae: 4.11, Validation MAE: 3.25, Test MAE: 4.49, LR: 0.000500\n",
            "EarlyStopping counter: 14 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.73it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 45, Train mae: 3.96, Validation MAE: 3.04, Test MAE: 4.68, LR: 0.000500\n",
            "EarlyStopping counter: 15 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.47it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 46, Train mae: 3.88, Validation MAE: 3.03, Test MAE: 4.76, LR: 0.000500\n",
            "EarlyStopping counter: 16 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.75it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 47, Train mae: 3.82, Validation MAE: 3.05, Test MAE: 4.51, LR: 0.000500\n",
            "EarlyStopping counter: 17 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.60it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 48, Train mae: 3.80, Validation MAE: 3.03, Test MAE: 4.44, LR: 0.000500\n",
            "EarlyStopping counter: 18 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.70it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 49, Train mae: 3.80, Validation MAE: 3.06, Test MAE: 4.46, LR: 0.000500\n",
            "EarlyStopping counter: 19 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.80it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50, Train mae: 3.60, Validation MAE: 3.32, Test MAE: 4.54, LR: 0.000500\n",
            "EarlyStopping counter: 20 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.35it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 51, Train mae: 3.72, Validation MAE: 3.09, Test MAE: 4.82, LR: 0.000500\n",
            "EarlyStopping counter: 21 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.73it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 52, Train mae: 3.51, Validation MAE: 3.17, Test MAE: 4.51, LR: 0.000500\n",
            "EarlyStopping counter: 22 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.08it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 53, Train mae: 3.39, Validation MAE: 3.32, Test MAE: 4.61, LR: 0.000500\n",
            "EarlyStopping counter: 23 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.64it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 54, Train mae: 3.59, Validation MAE: 3.22, Test MAE: 4.70, LR: 0.000500\n",
            "EarlyStopping counter: 24 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:03<00:00,  4.82it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 55, Train mae: 3.50, Validation MAE: 3.29, Test MAE: 4.76, LR: 0.000500\n",
            "EarlyStopping counter: 25 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.66it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 56, Train mae: 3.21, Validation MAE: 3.26, Test MAE: 4.78, LR: 0.000500\n",
            "EarlyStopping counter: 26 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.22it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 57, Train mae: 3.31, Validation MAE: 3.15, Test MAE: 4.44, LR: 0.000500\n",
            "EarlyStopping counter: 27 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.71it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 58, Train mae: 3.23, Validation MAE: 3.50, Test MAE: 4.80, LR: 0.000500\n",
            "EarlyStopping counter: 28 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.44it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 59, Train mae: 3.17, Validation MAE: 3.23, Test MAE: 4.72, LR: 0.000500\n",
            "EarlyStopping counter: 29 / 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:02<00:00,  5.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 60, Train mae: 3.12, Validation MAE: 3.26, Test MAE: 4.70, LR: 0.000500\n",
            "EarlyStopping counter: 30 / 30\n",
            "Early stopping triggered at epoch 60\n",
            "best validation results: 2.826950886955083\n",
            "best test results: 3.8405526310937446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4D3ONst6S0pI",
        "3JWVJkt7XmNa",
        "P-vR0q-lS3mL",
        "P6q-HPJfr7c_",
        "1gvkjcjPr7dB",
        "6xMIwSVTXXnr",
        "Nr7qtFXgr7dE",
        "kgdIEP05xmmg"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}