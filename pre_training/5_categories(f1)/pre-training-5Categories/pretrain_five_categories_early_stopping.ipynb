{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea-1704/Pytorch_Geometric_tutorial/blob/main/train_model_baseline_f1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx2yt6llLd5G"
      },
      "source": [
        "Facciamo adesso un pre training che sia molto simile al task effettivo e che sia supervisionato sul dataset di training andando a cercare di predire non la posizione corretta per il posizionamento di un pilota in una gara, ma piuttosto una categoria più semplice da predire.\n",
        "\n",
        "Categoria\tCondizione\n",
        "\n",
        "0\tVincitore → positionOrder == 1\n",
        "\n",
        "1\tPodio → positionOrder == 2 or 3\n",
        "\n",
        "2\tTop10 → positionOrder >= 4 and <= 10\n",
        "\n",
        "3\tFinisher dopo 10° → positionOrder > 10\n",
        "\n",
        "4\tRitirato o status anomalo → positionOrder == 0 oppure particolari statusId"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zNziUzq9nTdU"
      },
      "outputs": [],
      "source": [
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "\n",
        "# !pip install pytorch_frame[full]==1.2.2\n",
        "# !pip install relbench[full]==1.0.0\n",
        "# !pip uninstall -y pyg_lib torch  # Uninstall current versions\n",
        "# !pip install torch==2.6.0  # Reinstall your desired PyTorch version\n",
        "# !pip install --no-cache-dir git+https://github.com/pyg-team/pyg-lib.git # Install pyg-lib; --no-cache-dir ensures a fresh install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOWWxUxN1U3a"
      },
      "source": [
        "New libraries to run on colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UyHEamaV1U3b"
      },
      "outputs": [],
      "source": [
        "# !pip install torch==2.6.0+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "\n",
        "# !pip install pytorch_frame[full]==1.2.2\n",
        "# !pip install relbench[full]==1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yigMbymZe5d0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F454ta1Zg0Oq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.tasks import get_task\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import torch_geometric\n",
        "import torch_frame\n",
        "from torch_geometric.seed import seed_everything\n",
        "from relbench.modeling.utils import get_stype_proposal\n",
        "from collections import defaultdict\n",
        "import requests\n",
        "from io import StringIO\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "import pyg_lib\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#per lo scheduler\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "#import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBiKBpiV1U3c"
      },
      "source": [
        "# Dataset and task creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DWB-Kf6nl2y",
        "outputId": "f9c338f9-b94b-4c7a-b8c9-ba09f4af3bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading file 'rel-f1/db.zip' from 'https://relbench.stanford.edu/download/rel-f1/db.zip' to '/root/.cache/relbench'.\n",
            "100%|████████████████████████████████████████| 704k/704k [00:00<00:00, 488MB/s]\n",
            "Unzipping contents of '/root/.cache/relbench/rel-f1/db.zip' to '/root/.cache/relbench/rel-f1/.'\n",
            "Downloading file 'rel-f1/tasks/driver-position.zip' from 'https://relbench.stanford.edu/download/rel-f1/tasks/driver-position.zip' to '/root/.cache/relbench'.\n",
            "100%|█████████████████████████████████████| 36.5k/36.5k [00:00<00:00, 38.8MB/s]\n",
            "Unzipping contents of '/root/.cache/relbench/rel-f1/tasks/driver-position.zip' to '/root/.cache/relbench/rel-f1/tasks/.'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Loading Database object from /root/.cache/relbench/rel-f1/db...\n",
            "Done in 0.06 seconds.\n"
          ]
        }
      ],
      "source": [
        "dataset = get_dataset(\"rel-f1\", download=True)\n",
        "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
        "\n",
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")\n",
        "\n",
        "out_channels = 1\n",
        "# one because we are estimating one single value.\n",
        "loss_fn = L1Loss()\n",
        "# this is the mae loss and is used when have regressions tasks.\n",
        "tune_metric = \"mae\"\n",
        "higher_is_better = False\n",
        "\n",
        "seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "root_dir = \"./data\"\n",
        "\n",
        "db = dataset.get_db()\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "#this is used to get the stype of the columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElqMK-iU1U3d"
      },
      "source": [
        "# Embedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QQHYmgIxkX1j"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from typing import List, Optional\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from torch import Tensor\n",
        "\n",
        "\n",
        "# class GloveTextEmbedding:\n",
        "#     def __init__(self, device: Optional[torch.device\n",
        "#                                        ] = None):\n",
        "#         self.model = SentenceTransformer(\n",
        "#             \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "#             device=device,\n",
        "#         )\n",
        "\n",
        "#     def __call__(self, sentences: List[str]) -> Tensor:\n",
        "#         return torch.from_numpy(self.model.encode(sentences))\n",
        "\n",
        "\n",
        "class LightweightGloveEmbedder:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device\n",
        "        self.embeddings = defaultdict(lambda: np.zeros(300))\n",
        "        self._load_embeddings()\n",
        "\n",
        "    def _load_embeddings(self):\n",
        "        try:\n",
        "            #(senza bisogno di estrarre zip\n",
        "            url = \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt\"\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            for line in StringIO(response.text):\n",
        "                parts = line.split()\n",
        "                word = parts[0]\n",
        "                vector = np.array(parts[1:], dtype=np.float32)\n",
        "                self.embeddings[word] = vector\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Couldn't load GloVe embeddings ({str(e)}). Using zero vectors.\")\n",
        "\n",
        "    def __call__(self, sentences):\n",
        "        results = []\n",
        "        for text in sentences:\n",
        "            words = text.lower().split()\n",
        "            vectors = [self.embeddings[w] for w in words if w in self.embeddings]\n",
        "            if vectors:\n",
        "                avg_vector = np.mean(vectors, axis=0)\n",
        "            else:\n",
        "                avg_vector = np.zeros(300)\n",
        "            results.append(avg_vector)\n",
        "\n",
        "        tensor = torch.tensor(np.array(results), dtype=torch.float32)\n",
        "        return tensor.to(self.device) if self.device else tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-BBpUrakdwY",
        "outputId": "cc77a693-7237-4b06-e050-bb3cb1e01c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Couldn't load GloVe embeddings (404 Client Error: Not Found for url: https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt). Using zero vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 777.59it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 705.52it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 1602.10it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 1088.51it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 1295.74it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 1330.79it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 1351.91it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 1303.49it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/data/stats.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  ser = pd.to_datetime(ser, format=time_format)\n",
            "Embedding raw data in mini-batch: 100%|██████████| 4/4 [00:00<00:00, 1012.57it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/data/mapper.py:291: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  ser = pd.to_datetime(ser, format=self.format, errors='coerce')\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 915.79it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 966.43it/s]\n",
            "Embedding raw data in mini-batch: 100%|██████████| 1/1 [00:00<00:00, 1068.61it/s]\n"
          ]
        }
      ],
      "source": [
        "text_embedder_cfg = TextEmbedderConfig(\n",
        "    text_embedder=LightweightGloveEmbedder(device=device), batch_size=256\n",
        ")\n",
        "\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    #Solution if not working: !pip install --upgrade torch torchvision transformers\n",
        "    db,\n",
        "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
        "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
        "    cache_dir=os.path.join(\n",
        "        root_dir, f\"rel-f1_materialized_cache\"\n",
        "    ),  # store materialized graph for convenience\n",
        ")# create a graph how relbench requires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HUHVG-g6lM-b"
      },
      "outputs": [],
      "source": [
        "loader_dict = {}\n",
        "\n",
        "for split, table in [\n",
        "    (\"train\", train_table),\n",
        "    (\"val\", val_table),\n",
        "    (\"test\", test_table),\n",
        "]:\n",
        "    table_input = get_node_train_table_input(\n",
        "        table=table,\n",
        "        task=task,\n",
        "    )#notice that table_input is an object with three elements: nodes, time and transform.\n",
        "    #nodes contains the input nodes\n",
        "    #time contains the time for each node\n",
        "    #transform is the tranformation to be applied to nodes\n",
        "    entity_table = table_input.nodes[0]\n",
        "    #we need to populate the loader_dict with three elements: \"train\", \"val\", and \"test\".\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=[\n",
        "            128 for i in range(2)\n",
        "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.nodes,\n",
        "        input_time=table_input.time,\n",
        "        transform=table_input.transform,\n",
        "        batch_size=512,\n",
        "        temporal_strategy=\"uniform\",\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=0,\n",
        "        persistent_workers=False,\n",
        "    )#this is the loader for grapg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J2qIPMh1U3e"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_gyC-hV1U3e"
      },
      "source": [
        "## graphormer layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aKifOjNW1U3g"
      },
      "outputs": [],
      "source": [
        "_spatial_bias_cache = None\n",
        "_node_offset_cache = None\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def compute_spatial_bias(edge_index_dict, x_dict):\n",
        "    global _spatial_bias_cache, _node_offset_cache\n",
        "    if _spatial_bias_cache is not None:\n",
        "        return _spatial_bias_cache, _node_offset_cache\n",
        "    #creiamo un grafo diretto con Networkx\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    node_offset = {}\n",
        "    curr_offset = 0\n",
        "\n",
        "    #aggiungiamo i nodi con offset per mantenere indici globali univoci\n",
        "    for node_type, x in x_dict.items():\n",
        "        node_offset[node_type] = curr_offset\n",
        "        for i in range(x.size(0)):\n",
        "            G.add_node(curr_offset + i, type=node_type)\n",
        "        curr_offset += x.size(0)\n",
        "\n",
        "    #Aggiungiamo gli archi con offset\n",
        "    for (src_type, _, dst_type), edge_index in edge_index_dict.items():\n",
        "        src_offset = node_offset[src_type]\n",
        "        dst_offset = node_offset[dst_type]\n",
        "        src, dst = edge_index\n",
        "        for s, d in zip(src.tolist(), dst.tolist()):\n",
        "            G.add_edge(src_offset + s, dst_offset + d)\n",
        "\n",
        "\n",
        "    spatial_bias = defaultdict(lambda: -1)\n",
        "\n",
        "\n",
        "\n",
        "    for node in G.nodes():\n",
        "        lengths = nx.single_source_dijkstra_path_length(G, node)\n",
        "        for target, dist in lengths.items():\n",
        "            spatial_bias[(node, target)] = dist\n",
        "        #quelli non raggiungibili li lasciamo con default value, ovvero -1\n",
        "\n",
        "    _spatial_bias_cache = spatial_bias\n",
        "    _node_offset_cache = node_offset\n",
        "\n",
        "    return spatial_bias, node_offset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CBqSsq2C1U3g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import Linear\n",
        "from torch_geometric.utils import softmax\n",
        "from torch_geometric.utils import degree\n",
        "from collections import defaultdict\n",
        "\n",
        "class HeteroGraphormerLayerComplete(nn.Module):\n",
        "    def __init__(self, channels, edge_types, device, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.num_heads = num_heads\n",
        "        self.channels = channels\n",
        "        self.head_dim = channels // num_heads\n",
        "\n",
        "        assert self.channels % num_heads == 0, \"channels must be divisible by num_heads\"\n",
        "\n",
        "        self.q_lin = Linear(channels, channels)\n",
        "        self.k_lin = Linear(channels, channels)\n",
        "        self.v_lin = Linear(channels, channels)\n",
        "        self.out_lin = Linear(channels, channels)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(channels)\n",
        "\n",
        "        self.edge_type_bias = nn.ParameterDict({\n",
        "            \"__\".join(edge_type): nn.Parameter(torch.randn(1))\n",
        "            for edge_type in edge_types\n",
        "        })\n",
        "\n",
        "    def compute_total_degrees(self, x_dict, edge_index_dict):\n",
        "        device = self.device\n",
        "        in_deg = defaultdict(lambda: torch.zeros(0, device=device))\n",
        "        out_deg = defaultdict(lambda: torch.zeros(0, device=device))\n",
        "        for edge_type, edge_index in edge_index_dict.items():\n",
        "            src_type, _, dst_type = edge_type\n",
        "            src = edge_index[0]\n",
        "            dst = edge_index[1]\n",
        "\n",
        "            num_src = x_dict[src_type].size(0)\n",
        "            num_dst = x_dict[dst_type].size(0)\n",
        "\n",
        "            if out_deg[src_type].numel() == 0:\n",
        "                out_deg[src_type] = torch.zeros(num_src, device=device)\n",
        "            if in_deg[dst_type].numel() == 0:\n",
        "                in_deg[dst_type] = torch.zeros(num_dst, device=device)\n",
        "\n",
        "            out_deg[src_type] += degree(src, num_nodes=num_src)\n",
        "            in_deg[dst_type]  += degree(dst, num_nodes=num_dst)\n",
        "\n",
        "        total_deg = {\n",
        "            node_type: in_deg[node_type] + out_deg[node_type]\n",
        "            for node_type in x_dict\n",
        "        }\n",
        "\n",
        "        return total_deg\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        self.spatial_bias, self.node_offset = compute_spatial_bias(edge_index_dict, x_dict)\n",
        "\n",
        "        out_dict = {k: torch.zeros_like(v) for k, v in x_dict.items()}\n",
        "        for edge_type, edge_index in edge_index_dict.items():\n",
        "            src_type, _, dst_type = edge_type\n",
        "            x_src, x_dst = x_dict[src_type], x_dict[dst_type]\n",
        "\n",
        "            #src, dst = edge_index\n",
        "            src = edge_index[0]\n",
        "            dst = edge_index[1]\n",
        "\n",
        "            Q = self.q_lin(x_dst).view(-1, self.num_heads, self.head_dim)\n",
        "            K = self.k_lin(x_src).view(-1, self.num_heads, self.head_dim)\n",
        "            V = self.v_lin(x_src).view(-1, self.num_heads, self.head_dim)\n",
        "\n",
        "            attn_scores = (Q[dst] * K[src]).sum(dim=-1) / self.head_dim**0.5\n",
        "            src_offset = self.node_offset[src_type]\n",
        "            dst_offset = self.node_offset[dst_type]\n",
        "\n",
        "            spatial_bias_vals = []\n",
        "            for s, d in zip(src.tolist(), dst.tolist()):\n",
        "                global_s = src_offset + s\n",
        "                global_d = dst_offset + d\n",
        "                dist = self.spatial_bias.get((global_d, global_s), -1.0)\n",
        "                spatial_bias_vals.append(dist)\n",
        "\n",
        "            spatial_bias_tensor = torch.tensor(spatial_bias_vals, dtype=torch.float, device=self.device)\n",
        "            attn_scores = attn_scores + spatial_bias_tensor.unsqueeze(-1)\n",
        "\n",
        "            bias_name = \"__\".join(edge_type)\n",
        "            attn_scores = attn_scores + self.edge_type_bias[bias_name]\n",
        "\n",
        "            attn_weights = softmax(attn_scores, dst)\n",
        "            attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "            out = V[src] * attn_weights.unsqueeze(-1)\n",
        "            out = out.view(-1, self.channels)\n",
        "\n",
        "            out_dict[dst_type].index_add_(0, dst, out)\n",
        "\n",
        "        total_deg = self.compute_total_degrees(x_dict, edge_index_dict)\n",
        "\n",
        "        for node_type in out_dict:\n",
        "            # Assicurati che total_deg[node_type] sia della forma corretta (num_nodes, 1)\n",
        "            degree_embed = total_deg[node_type].view(-1, 1)                                                                                  # Assicurati che sia una colonna\n",
        "            degree_embed = degree_embed.expand(-1, self.channels)                                                                            # Espandi lungo la dimensione dei canali\n",
        "\n",
        "            # Somma l'embedding con la degree centrality\n",
        "            out_dict[node_type] = out_dict[node_type] + degree_embed\n",
        "\n",
        "        # Normalizzazione finale\n",
        "        for node_type in out_dict:\n",
        "            out_dict[node_type] = self.norm(out_dict[node_type] + x_dict[node_type])\n",
        "\n",
        "        return out_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR6g_lwH1U3h"
      },
      "source": [
        "## HeteroGraphormer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0rbfjsM51U3h"
      },
      "outputs": [],
      "source": [
        "class HeteroGraphormer(torch.nn.Module):\n",
        "    def __init__(self, node_types, edge_types, channels, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.ModuleList([\n",
        "            HeteroGraphormerLayerComplete(channels, edge_types, device) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, *args, **kwargs):\n",
        "        for layer in self.layers:\n",
        "            x_dict = layer(x_dict, edge_index_dict)\n",
        "        return x_dict\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for layer in self.layers:\n",
        "            if hasattr(layer, \"reset_parameters\"):\n",
        "                layer.reset_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u3m3jEqClQnw"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData, #notice that \"data2 is the graph we created with function make_pkey_fkey_graph\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        # List of node types to add shallow embeddings to input\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        # ID awareness\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "        self.gnn = HeteroGraphormer(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,#one, since we are doing regression\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward_for_embedding(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        # Come la forward ma senza usare seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        # Se c'è l'embedding ID-aware lo aggiungiamo\n",
        "        if self.id_awareness_emb is not None:\n",
        "            for node_type in x_dict:\n",
        "                x_dict[node_type] += self.id_awareness_emb.weight\n",
        "\n",
        "        if hasattr(batch[entity_table], \"time\"):  # fallback se vuoi usare il tempo\n",
        "            rel_time_dict = self.temporal_encoder(\n",
        "                batch[entity_table].time,  # oppure seed_time se esiste\n",
        "                batch.time_dict,\n",
        "                batch.batch_dict,\n",
        "            )\n",
        "            for node_type, rel_time in rel_time_dict.items():\n",
        "                x_dict[node_type] += rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] += embedding(batch[node_type].n_id)\n",
        "\n",
        "        z_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )\n",
        "\n",
        "        return z_dict[entity_table]  # restituisce tutti gli embeddings per quel nodo\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        pretrain_mode: bool = False\n",
        "    ) -> Tensor:\n",
        "\n",
        "        if pretrain_mode:\n",
        "            # Pretraining: NON usiamo seed_time\n",
        "            x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "            rel_time_dict = self.temporal_encoder(\n",
        "                batch[entity_table].time,  # <-- qui prendi solo il tempo dei nodi centrali\n",
        "                batch.time_dict,\n",
        "                batch.batch_dict\n",
        "            )\n",
        "\n",
        "            for node_type, rel_time in rel_time_dict.items():\n",
        "                x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "            for node_type, embedding in self.embedding_dict.items():\n",
        "                x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "            x_dict = self.gnn(\n",
        "                x_dict,\n",
        "                batch.edge_index_dict,\n",
        "                batch.num_sampled_nodes_dict,\n",
        "                batch.num_sampled_edges_dict,\n",
        "            )\n",
        "\n",
        "            # Predici solo sui nodi centrali (batch == 0)\n",
        "            mask = (batch[entity_table].batch == 0)\n",
        "            return self.head(x_dict[entity_table])  # senza mascherare\n",
        "\n",
        "\n",
        "        else:\n",
        "            # Caso normale downstream\n",
        "            seed_time = batch[entity_table].seed_time\n",
        "            x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "            rel_time_dict = self.temporal_encoder(\n",
        "                seed_time,\n",
        "                batch.time_dict,\n",
        "                batch.batch_dict\n",
        "            )\n",
        "\n",
        "            for node_type, rel_time in rel_time_dict.items():\n",
        "                x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "            for node_type, embedding in self.embedding_dict.items():\n",
        "                x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "            x_dict = self.gnn(\n",
        "                x_dict,\n",
        "                batch.edge_index_dict,\n",
        "                batch.num_sampled_nodes_dict,\n",
        "                batch.num_sampled_edges_dict,\n",
        "            )\n",
        "\n",
        "            return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
        "\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        # Add ID-awareness to the root node\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=2,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"sum\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl-6So7Llb-p"
      },
      "source": [
        "We also need standard train/test loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRkxm09h2RAJ"
      },
      "source": [
        "## pre training function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ArHwjF4MqjG"
      },
      "source": [
        "Funzione per mappare la posizione in una delle cinque categorie:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gXX9vyNYMubA"
      },
      "outputs": [],
      "source": [
        "def map_position_to_category(position_order, status_id):\n",
        "    \"\"\"\n",
        "    Mappa il positionOrder (e statusId) in 5 categorie:\n",
        "    0: Vincitore\n",
        "    1: Podio (2-3)\n",
        "    2: Top10 (4-10)\n",
        "    3: Finisher dopo 10\n",
        "    4: Ritirato\n",
        "    \"\"\"\n",
        "    category = torch.full_like(position_order, fill_value=3)  # Default: finisher >10\n",
        "    category[position_order == 1] = 0\n",
        "    category[(position_order == 2) | (position_order == 3)] = 1\n",
        "    category[(position_order >= 4) & (position_order <= 10)] = 2\n",
        "    category[position_order == 0] = 4  # Ritirato o anomalia\n",
        "\n",
        "    return category\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaWUjhszMzXt"
      },
      "source": [
        "Codice di pre training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "deL6_x3FM1xk"
      },
      "outputs": [],
      "source": [
        "def pretrain_race_category_loop(model, optimizer, loader, loss_fn, device, entity_table='results'):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_count = 0\n",
        "\n",
        "    for batch in tqdm(loader):\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward embeddings\n",
        "        predictions = model(batch, entity_table=entity_table, pretrain_mode=True)\n",
        "        if predictions is None or len(predictions) == 0:\n",
        "            continue\n",
        "\n",
        "        # 1. Prendi i campi tf\n",
        "        tf = batch[entity_table].tf\n",
        "        status_id = tf.feat_dict[next(iter(tf.feat_dict))][:, tf.col_names_dict[next(iter(tf.feat_dict))].index('statusId')]\n",
        "        position_order = tf.feat_dict[next(iter(tf.feat_dict))][:, tf.col_names_dict[next(iter(tf.feat_dict))].index('positionOrder')]\n",
        "\n",
        "        # 2. Costruisci i targets\n",
        "        targets = map_position_to_category(position_order, status_id)\n",
        "\n",
        "        # 3. Maschera per prendere solo i nodi centrali\n",
        "        mask = (batch[entity_table].batch == 0)\n",
        "\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        # 4. Applica il mask sia a predictions che a targets\n",
        "        preds = predictions[mask]\n",
        "        targets = targets[mask].to(device).long()\n",
        "\n",
        "\n",
        "        # 5. Loss\n",
        "        loss = loss_fn(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_count += 1\n",
        "\n",
        "    return total_loss / total_count if total_count > 0 else 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlR9IuwW1U3i"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zm1uM_ij1U3i"
      },
      "outputs": [],
      "source": [
        "def get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps, num_cycles=0.5):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < warmup_steps:\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "        progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * num_cycles * 2 * progress)))\n",
        "\n",
        "    return LambdaLR(optimizer, lr_lambda)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Py_olFY1U3i"
      },
      "source": [
        "Dobbiamo modificare la funzione di training in modo da ricevere correttamente uno scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SAHRIr15lVs6"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, scheduler) -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "#        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred = pred.view(-1) if pred.dim() == 2 and pred.size(1) == 1 else pred\n",
        "\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        #pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        if pred.dim() == 2 and pred.size(1) == 1:\n",
        "           pred = pred.view(-1)\n",
        "\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iRKOx4Wf1U3i"
      },
      "outputs": [],
      "source": [
        "def rmse(true, pred):\n",
        "    \"\"\"Calculate the Root Mean Squared Error (RMSE).\"\"\"\n",
        "    return np.sqrt(np.mean((true - pred)**2)) # Calculate RMSE manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qZOOyAblHwI4"
      },
      "outputs": [],
      "source": [
        "def custom_evaluate(pred: np.ndarray, target_table, metrics) -> dict:\n",
        "    \"\"\"Custom evaluation function to replace task.evaluate.\"\"\"\n",
        "\n",
        "    # Extract target values from the target table\n",
        "    target = target_table.df[task.target_col].to_numpy()\n",
        "\n",
        "    # Check for length mismatch\n",
        "    if len(pred) != len(target):\n",
        "        raise ValueError(\n",
        "            f\"The length of pred and target must be the same (got \"\n",
        "            f\"{len(pred)} and {len(target)}, respectively).\"\n",
        "        )\n",
        "\n",
        "    # Calculate metrics\n",
        "    results = {}\n",
        "    for metric_fn in metrics:\n",
        "        if metric_fn.__name__ == \"rmse\":  # Handle RMSE specifically\n",
        "            results[\"rmse\"] = np.sqrt(np.mean((target - pred)**2))\n",
        "        else:  # Handle other metrics (if any)\n",
        "            results[metric_fn.__name__] = metric_fn(target, pred)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KkWi72Qd1U3m"
      },
      "outputs": [],
      "source": [
        "def training_function(model, optimizer, epochs):\n",
        "    state_dict = None\n",
        "    best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, optimizer)\n",
        "        val_pred = test(model, loader_dict[\"val\"])\n",
        "        #val_metrics = task.evaluate(val_pred, val_table)\n",
        "        val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "        #print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "        if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "        ):\n",
        "            best_val_metric = val_metrics[tune_metric]\n",
        "            state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "    print(f\"Best Val metrics for parameters {optimizer}, are: {val_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMnS7MFx1U3m"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5DlP_AT1U3n"
      },
      "source": [
        "Andiamo a plottare i valori delle metriche durante il training per avere una visione più avanzata su come stia procedendo il processo di training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iwt_B51N1U3n"
      },
      "outputs": [],
      "source": [
        "def plot_validation_metrics(metric_histories, model_names=None, metric_name=\"MAE\", informationsTitle=\"\"):\n",
        "    \"\"\"\n",
        "    Plotta l'andamento del metric_name per più modelli nel tempo.\n",
        "\n",
        "    Args:\n",
        "        metric_histories (list of lists): Lista di liste, ognuna rappresenta i valori di metriche per un modello.\n",
        "        model_names (list of str): Nomi dei modelli (opzionale).\n",
        "        metric_name (str): Nome della metrica da visualizzare.\n",
        "        informationsTitle (str): info aggiungitive da mettere nel titolo (conf generale dei parametri ecc).\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(9, 5))\n",
        "\n",
        "    if model_names is None:\n",
        "        model_names = [f\"Model {i+1}\" for i in range(len(metric_histories))]\n",
        "\n",
        "    for metrics, name in zip(metric_histories, model_names):\n",
        "        plt.plot(metrics, marker='o', label=f'{name} {metric_name}')\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.title(f\"{metric_name} over Epochs for Multiple Models {informationsTitle}\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF3W68Eqlew_",
        "outputId": "7cc5c3a4-7d08-4fd4-8b56-de2056838dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:26<00:00,  1.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 - Pretraining Loss: 1.2599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 - Pretraining Loss: 0.7665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100 - Pretraining Loss: 0.4434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 - Pretraining Loss: 0.1767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100 - Pretraining Loss: 0.5477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 - Pretraining Loss: 0.4103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100 - Pretraining Loss: 0.4102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 - Pretraining Loss: 0.3052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 - Pretraining Loss: 0.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 - Pretraining Loss: 0.2647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 - Pretraining Loss: 0.1408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 - Pretraining Loss: 0.1715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100 - Pretraining Loss: 0.0966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100 - Pretraining Loss: 0.2375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100 - Pretraining Loss: 0.3769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100 - Pretraining Loss: 0.1549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100 - Pretraining Loss: 0.2149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100 - Pretraining Loss: 0.1906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100 - Pretraining Loss: 0.1506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100 - Pretraining Loss: 0.1200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100 - Pretraining Loss: 0.1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100 - Pretraining Loss: 0.1918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100 - Pretraining Loss: 0.0874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/100 - Pretraining Loss: 0.0581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/100 - Pretraining Loss: 0.4887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100 - Pretraining Loss: 0.2300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100 - Pretraining Loss: 0.2093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100 - Pretraining Loss: 0.1617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100 - Pretraining Loss: 0.0716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100 - Pretraining Loss: 0.0660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100 - Pretraining Loss: 0.0808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100 - Pretraining Loss: 0.1146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100 - Pretraining Loss: 0.0748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100 - Pretraining Loss: 0.1675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100 - Pretraining Loss: 0.0363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/100 - Pretraining Loss: 0.0499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/100 - Pretraining Loss: 0.2166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/100 - Pretraining Loss: 0.3955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/100 - Pretraining Loss: 0.2642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/100 - Pretraining Loss: 0.2825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/100 - Pretraining Loss: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/100 - Pretraining Loss: 0.0772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/100 - Pretraining Loss: 0.0236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/100 - Pretraining Loss: 0.0603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/100 - Pretraining Loss: 0.0598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/100 - Pretraining Loss: 0.0265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/100 - Pretraining Loss: 0.0379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/100 - Pretraining Loss: 0.0242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/100 - Pretraining Loss: 0.0191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/100 - Pretraining Loss: 0.0573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/100 - Pretraining Loss: 0.0255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/100 - Pretraining Loss: 0.1613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/100 - Pretraining Loss: 0.0441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/100 - Pretraining Loss: 0.0488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/100 - Pretraining Loss: 0.0319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/100 - Pretraining Loss: 0.0198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/100 - Pretraining Loss: 0.0312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/100 - Pretraining Loss: 0.0333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/100 - Pretraining Loss: 0.1348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/100 - Pretraining Loss: 0.0152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/100 - Pretraining Loss: 0.0684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62/100 - Pretraining Loss: 0.0980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63/100 - Pretraining Loss: 0.0522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64/100 - Pretraining Loss: 0.0806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65/100 - Pretraining Loss: 0.1340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/100 - Pretraining Loss: 0.0580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67/100 - Pretraining Loss: 0.0528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68/100 - Pretraining Loss: 0.0994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69/100 - Pretraining Loss: 0.1263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/100 - Pretraining Loss: 0.0411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71/100 - Pretraining Loss: 0.0641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72/100 - Pretraining Loss: 0.0373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/100 - Pretraining Loss: 0.0355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/100 - Pretraining Loss: 0.0107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75/100 - Pretraining Loss: 0.0258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76/100 - Pretraining Loss: 0.0601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77/100 - Pretraining Loss: 0.0316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78/100 - Pretraining Loss: 0.0134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79/100 - Pretraining Loss: 0.0134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80/100 - Pretraining Loss: 0.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81/100 - Pretraining Loss: 0.0301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82/100 - Pretraining Loss: 0.1662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83/100 - Pretraining Loss: 0.1518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84/100 - Pretraining Loss: 0.0230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85/100 - Pretraining Loss: 0.0311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86/100 - Pretraining Loss: 0.0964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87/100 - Pretraining Loss: 0.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88/100 - Pretraining Loss: 0.1230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89/100 - Pretraining Loss: 0.1222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90/100 - Pretraining Loss: 0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91/100 - Pretraining Loss: 0.0272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92/100 - Pretraining Loss: 0.0216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93/100 - Pretraining Loss: 0.0140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94/100 - Pretraining Loss: 0.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95/100 - Pretraining Loss: 0.0071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96/100 - Pretraining Loss: 0.0169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97/100 - Pretraining Loss: 0.0122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98/100 - Pretraining Loss: 0.0184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99/100 - Pretraining Loss: 0.0502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/100 - Pretraining Loss: 0.0210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_pretrain = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=1,\n",
        "    channels=128,\n",
        "    out_channels=5,  ####\n",
        "    aggr=\"sum\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)\n",
        "#nota che abbiamo 5 come out channel nel pre training task e poi solo uno nel training task\n",
        "\n",
        "\n",
        "loss_fn_pretrain = torch.nn.CrossEntropyLoss()\n",
        "optimizer_pretrain = torch.optim.Adam(model_pretrain.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss = pretrain_race_category_loop(\n",
        "        model=model_pretrain,\n",
        "        optimizer=optimizer_pretrain,\n",
        "        loader=loader_dict[\"train\"],\n",
        "        loss_fn=loss_fn_pretrain,\n",
        "        device=device,\n",
        "        entity_table=\"results\",\n",
        "    )\n",
        "    print(f\"Epoch {epoch}/{epochs} - Pretraining Loss: {loss:.4f}\")\n",
        "\n",
        "#salvo i pesi del modello:\n",
        "torch.save(model_pretrain.state_dict(), \"model_pretrained_race_category.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5urjIJEWzLY4"
      },
      "source": [
        "WE need an early stopping approach!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IPZmAkWnzLY4"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0, verbose=False, path='checkpoint.pt'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Quanto aspettare senza miglioramenti prima di fermare.\n",
        "            delta (float): Miglioramento minimo richiesto per considerare un miglioramento.\n",
        "            verbose (bool): Se stampare informazioni.\n",
        "            path (str): Dove salvare il modello migliore.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "        self.delta = delta\n",
        "        self.verbose = verbose\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss  # Perché vogliamo MINIMIZZARE la loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f'EarlyStopping counter: {self.counter} / {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Salva il modello migliore'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss migliorata ({self.val_loss_min:.6f} --> {val_loss:.6f}). Salvo modello...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-51t8n3XltMQ",
        "outputId": "72474541-309c-4225-da8d-75df145030bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 01, Train loss: 225.250569056812, Val metrics: {'r2': -3.2780883064288933, 'mae': 8.381909343092618, 'rmse': np.float64(9.589040701926635)}\n",
            "[VAL]----Epoch: 01, Val metrics: 8.381909343092618\n",
            "[TEST]----Epoch: 01, Val metrics: 10.235742747825489\n",
            "Validation loss migliorata (inf --> 8.381909). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 02, Train loss: 161.72609213088546, Val metrics: {'r2': -1.5510102746482075, 'mae': 6.222903656274697, 'rmse': np.float64(7.404681682888739)}\n",
            "[VAL]----Epoch: 02, Val metrics: 6.222903656274697\n",
            "[TEST]----Epoch: 02, Val metrics: 8.287283493510463\n",
            "Validation loss migliorata (8.381909 --> 6.222904). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 03, Train loss: 118.13472219999726, Val metrics: {'r2': -0.890573883523512, 'mae': 5.312364105933017, 'rmse': np.float64(6.37451454997144)}\n",
            "[VAL]----Epoch: 03, Val metrics: 5.312364105933017\n",
            "[TEST]----Epoch: 03, Val metrics: 6.896931668959166\n",
            "Validation loss migliorata (6.222904 --> 5.312364). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 04, Train loss: 97.41368904456698, Val metrics: {'r2': -0.524696967576445, 'mae': 4.783507041319577, 'rmse': np.float64(5.724559291669402)}\n",
            "[VAL]----Epoch: 04, Val metrics: 4.783507041319577\n",
            "[TEST]----Epoch: 04, Val metrics: 5.8555789125593085\n",
            "Validation loss migliorata (5.312364 --> 4.783507). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:08<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 05, Train loss: 84.10452861675844, Val metrics: {'r2': -0.2777003847407189, 'mae': 4.403051358887412, 'rmse': np.float64(5.240404397547379)}\n",
            "[VAL]----Epoch: 05, Val metrics: 4.403051358887412\n",
            "[TEST]----Epoch: 05, Val metrics: 5.219051511329518\n",
            "Validation loss migliorata (4.783507 --> 4.403051). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 06, Train loss: 73.53881483693483, Val metrics: {'r2': -0.09727373720647603, 'mae': 4.1032332566235175, 'rmse': np.float64(4.856325431820777)}\n",
            "[VAL]----Epoch: 06, Val metrics: 4.1032332566235175\n",
            "[TEST]----Epoch: 06, Val metrics: 4.78451012117821\n",
            "Validation loss migliorata (4.403051 --> 4.103233). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 07, Train loss: 64.50784177894035, Val metrics: {'r2': -0.0017050480862284, 'mae': 3.899082798088242, 'rmse': np.float64(4.6400239351534545)}\n",
            "[VAL]----Epoch: 07, Val metrics: 3.899082798088242\n",
            "[TEST]----Epoch: 07, Val metrics: 4.48774733869653\n",
            "Validation loss migliorata (4.103233 --> 3.899083). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 08, Train loss: 57.342230508779494, Val metrics: {'r2': 0.04207795744468801, 'mae': 3.767092375796719, 'rmse': np.float64(4.537486783363258)}\n",
            "[VAL]----Epoch: 08, Val metrics: 3.767092375796719\n",
            "[TEST]----Epoch: 08, Val metrics: 4.274592345639279\n",
            "Validation loss migliorata (3.899083 --> 3.767092). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 09, Train loss: 51.846990588654066, Val metrics: {'r2': 0.18736209840665896, 'mae': 3.46904334869079, 'rmse': np.float64(4.179254575949257)}\n",
            "[VAL]----Epoch: 09, Val metrics: 3.46904334869079\n",
            "[TEST]----Epoch: 09, Val metrics: 3.934683710817705\n",
            "Validation loss migliorata (3.767092 --> 3.469043). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 10, Train loss: 47.25795917928131, Val metrics: {'r2': 0.22273936622499513, 'mae': 3.3421573635093673, 'rmse': np.float64(4.087272806470681)}\n",
            "[VAL]----Epoch: 10, Val metrics: 3.3421573635093673\n",
            "[TEST]----Epoch: 10, Val metrics: 3.8363543103870597\n",
            "Validation loss migliorata (3.469043 --> 3.342157). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 11, Train loss: 43.854427522930315, Val metrics: {'r2': 0.17208900678231132, 'mae': 3.39366126006336, 'rmse': np.float64(4.218345178508892)}\n",
            "[VAL]----Epoch: 11, Val metrics: 3.39366126006336\n",
            "[TEST]----Epoch: 11, Val metrics: 3.9026283918765556\n",
            "EarlyStopping counter: 1 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 12, Train loss: 41.22445039635262, Val metrics: {'r2': 0.24459865172021633, 'mae': 3.2008361811946853, 'rmse': np.float64(4.029388730458844)}\n",
            "[VAL]----Epoch: 12, Val metrics: 3.2008361811946853\n",
            "[TEST]----Epoch: 12, Val metrics: 3.942870391711854\n",
            "Validation loss migliorata (3.342157 --> 3.200836). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 13, Train loss: 39.19655030042105, Val metrics: {'r2': 0.34107433027225964, 'mae': 2.929260582563952, 'rmse': np.float64(3.7632970753602177)}\n",
            "[VAL]----Epoch: 13, Val metrics: 2.929260582563952\n",
            "[TEST]----Epoch: 13, Val metrics: 3.964523140380257\n",
            "Validation loss migliorata (3.200836 --> 2.929261). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 14, Train loss: 37.772852145376326, Val metrics: {'r2': 0.35502293777058747, 'mae': 2.8719703272333446, 'rmse': np.float64(3.723251940489257)}\n",
            "[VAL]----Epoch: 14, Val metrics: 2.8719703272333446\n",
            "[TEST]----Epoch: 14, Val metrics: 4.038768251862442\n",
            "Validation loss migliorata (2.929261 --> 2.871970). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 15, Train loss: 36.887148308046996, Val metrics: {'r2': 0.32511326180630695, 'mae': 2.9813114740248117, 'rmse': np.float64(3.808603276619415)}\n",
            "[VAL]----Epoch: 15, Val metrics: 2.9813114740248117\n",
            "[TEST]----Epoch: 15, Val metrics: 4.131571087753564\n",
            "EarlyStopping counter: 1 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 16, Train loss: 36.22222284859304, Val metrics: {'r2': 0.36926761336136904, 'mae': 2.83934340480175, 'rmse': np.float64(3.6819073459160623)}\n",
            "[VAL]----Epoch: 16, Val metrics: 2.83934340480175\n",
            "[TEST]----Epoch: 16, Val metrics: 4.242418306794083\n",
            "Validation loss migliorata (2.871970 --> 2.839343). Salvo modello...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 17, Train loss: 35.65789792823357, Val metrics: {'r2': 0.273308280476542, 'mae': 3.08338049689212, 'rmse': np.float64(3.952076980493204)}\n",
            "[VAL]----Epoch: 17, Val metrics: 3.08338049689212\n",
            "[TEST]----Epoch: 17, Val metrics: 4.337347810561197\n",
            "EarlyStopping counter: 1 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 18, Train loss: 35.07329457675981, Val metrics: {'r2': 0.3179645988915465, 'mae': 2.9460014142588764, 'rmse': np.float64(3.828721246487221)}\n",
            "[VAL]----Epoch: 18, Val metrics: 2.9460014142588764\n",
            "[TEST]----Epoch: 18, Val metrics: 4.387169666750389\n",
            "EarlyStopping counter: 2 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 19, Train loss: 34.80020967598939, Val metrics: {'r2': 0.2951349573847598, 'mae': 2.9976140785472105, 'rmse': np.float64(3.892272840957129)}\n",
            "[VAL]----Epoch: 19, Val metrics: 2.9976140785472105\n",
            "[TEST]----Epoch: 19, Val metrics: 4.4662328126555995\n",
            "EarlyStopping counter: 3 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 20, Train loss: 34.54926101559683, Val metrics: {'r2': 0.28956300950750524, 'mae': 3.042397822008662, 'rmse': np.float64(3.907626737612419)}\n",
            "[VAL]----Epoch: 20, Val metrics: 3.042397822008662\n",
            "[TEST]----Epoch: 20, Val metrics: 4.5239794403210025\n",
            "EarlyStopping counter: 4 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 21, Train loss: 34.42389740886967, Val metrics: {'r2': 0.3169429726104288, 'mae': 2.9941385476845617, 'rmse': np.float64(3.8315877095498716)}\n",
            "[VAL]----Epoch: 21, Val metrics: 2.9941385476845617\n",
            "[TEST]----Epoch: 21, Val metrics: 4.522058911198064\n",
            "EarlyStopping counter: 5 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 22, Train loss: 34.10180428132713, Val metrics: {'r2': 0.3567606920985086, 'mae': 2.8613975829415583, 'rmse': np.float64(3.71823279987887)}\n",
            "[VAL]----Epoch: 22, Val metrics: 2.8613975829415583\n",
            "[TEST]----Epoch: 22, Val metrics: 4.540273563150774\n",
            "EarlyStopping counter: 6 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 23, Train loss: 33.608445651608314, Val metrics: {'r2': 0.3008455373740456, 'mae': 3.0044286108685876, 'rmse': np.float64(3.8764738322509364)}\n",
            "[VAL]----Epoch: 23, Val metrics: 3.0044286108685876\n",
            "[TEST]----Epoch: 23, Val metrics: 4.437704352286824\n",
            "EarlyStopping counter: 7 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 24, Train loss: 33.42958492850771, Val metrics: {'r2': 0.31049856962338074, 'mae': 2.9833227669786595, 'rmse': np.float64(3.849620118735397)}\n",
            "[VAL]----Epoch: 24, Val metrics: 2.9833227669786595\n",
            "[TEST]----Epoch: 24, Val metrics: 4.442044740476105\n",
            "EarlyStopping counter: 8 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 25, Train loss: 33.13374779999504, Val metrics: {'r2': 0.2651863229396777, 'mae': 3.097540748891786, 'rmse': np.float64(3.9741010450447574)}\n",
            "[VAL]----Epoch: 25, Val metrics: 3.097540748891786\n",
            "[TEST]----Epoch: 25, Val metrics: 4.419093698409566\n",
            "EarlyStopping counter: 9 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN]----Epoch: 26, Train loss: 32.82930244651558, Val metrics: {'r2': 0.3343087141923664, 'mae': 2.9355894553478192, 'rmse': np.float64(3.782567838030329)}\n",
            "[VAL]----Epoch: 26, Val metrics: 2.9355894553478192\n",
            "[TEST]----Epoch: 26, Val metrics: 4.271720745270713\n",
            "EarlyStopping counter: 10 / 10\n",
            "Early stopping at epoch 26\n",
            "Best Val metrics: {'r2': 0.3697039888708211, 'mae': 2.832426402309216, 'rmse': np.float64(3.68063345208724)}\n",
            "Best test metrics: {'r2': 0.17690831807296192, 'mae': 3.8352896672800965, 'rmse': np.float64(4.727090992875617)}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#####TRAINING####\n",
        "early_stopping = EarlyStopping(patience=10, verbose=True, path=\"best_model.pt\")\n",
        "\n",
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=1,\n",
        "    channels=128,\n",
        "    out_channels=1,  # <-- Adesso 1 output continuo\n",
        "    aggr=\"sum\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)\n",
        "\n",
        "# model.load_state_dict(\n",
        "#     torch.load(\"model_pretrained_race_category.pth\"),\n",
        "#     strict=False\n",
        "# )\n",
        "# 1. Carica tutto il checkpoint\n",
        "pretrained_dict = torch.load(\"model_pretrained_race_category.pth\")\n",
        "\n",
        "# 2. Prendi solo i pesi che non sono della testa\n",
        "filtered_dict = {k: v for k, v in pretrained_dict.items() if not k.startswith('head')}\n",
        "\n",
        "# 3. Carica i pesi filtrati nel nuovo modello\n",
        "model.load_state_dict(filtered_dict, strict=False)\n",
        "\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
        "\n",
        "epochs = 100\n",
        "total_steps = epochs * len(loader_dict[\"train\"])\n",
        "warmup_steps = int(0.1 * total_steps)  # 10% warmup\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "state_dict = None\n",
        "state_dict_test = None\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "best_test_metric = -math.inf if higher_is_better else math.inf\n",
        "test_table = task.get_table(\"test\", mask_input_cols=False)\n",
        "\n",
        "#per mantenere la storia dei MAE nel tempo:\n",
        "val_metr_history = []\n",
        "test_metr_history = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(model, optimizer, scheduler)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    #val_metrics = task.evaluate(val_pred, val_table)\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "\n",
        "    test_pred = test(model, loader_dict[\"test\"])\n",
        "    test_metrics = custom_evaluate(test_pred, test_table, task.metrics)\n",
        "\n",
        "    val_metr_history.append(val_metrics[tune_metric])\n",
        "    test_metr_history.append(test_metrics[tune_metric])\n",
        "\n",
        "    print(f\"[TRAIN]----Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "    print(f\"[VAL]----Epoch: {epoch:02d}, Val metrics: {val_metrics[tune_metric]}\")\n",
        "    print(f\"[TEST]----Epoch: {epoch:02d}, Val metrics: {test_metrics[tune_metric]}\")\n",
        "\n",
        "    early_stopping(val_metrics[tune_metric], model)\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "        print(f\"Early stopping at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    #test:\n",
        "    if (higher_is_better and test_metrics[tune_metric] > best_test_metric) or (\n",
        "            not higher_is_better and test_metrics[tune_metric] < best_test_metric\n",
        "    ):\n",
        "        best_test_metric = test_metrics[tune_metric]\n",
        "        state_dict_test = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "val_pred = test(model, loader_dict[\"val\"])\n",
        "val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "print(f\"Best Val metrics: {val_metrics}\")\n",
        "\n",
        "model.load_state_dict(state_dict_test)\n",
        "test_pred = test(model,loader_dict[\"test\"])\n",
        "test_metrics = custom_evaluate(test_pred, test_table, task.metrics)\n",
        "print(f\"Best test metrics: {test_metrics}\")\n",
        "\n",
        "plot_validation_metrics([val_metr_history], [\"basic model\"],  metric_name=tune_metric)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}