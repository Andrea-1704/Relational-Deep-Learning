{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea-1704/AML-labs/blob/main/rel_trial_maskesd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAnf26iN5QYQ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D3ONst6S0pI"
      },
      "source": [
        "# Libraries to install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNziUzq9nTdU"
      },
      "outputs": [],
      "source": [
        "# !pip install torch==2.6.0+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "\n",
        "# !pip install pytorch_frame[full]==1.2.2\n",
        "# !pip install relbench[full]==1.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnQsMT_H0Cd5"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4CRrrOj0Dyp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.tasks import get_task\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import torch_geometric\n",
        "import torch_frame\n",
        "from torch_geometric.seed import seed_everything\n",
        "from relbench.modeling.utils import get_stype_proposal\n",
        "from collections import defaultdict\n",
        "import requests\n",
        "from io import StringIO\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "import pyg_lib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.nn import ModuleDict, Linear\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "from torch_frame.data.stats import StatType\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from typing import Dict, List, Tuple\n",
        "from torch import Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSMCBUtnzpMC"
      },
      "source": [
        "# Dataset and Task definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zruWlLpzT6ng"
      },
      "outputs": [],
      "source": [
        "def get_stype_enum_with_value(full_stype_dict, target_value: str):\n",
        "    for table_entry in full_stype_dict.values():\n",
        "        if isinstance(table_entry, dict):\n",
        "            for val in table_entry.values():\n",
        "                if str(val) == target_value:\n",
        "                    return val\n",
        "    raise ValueError(f\"Tipo '{target_value}' non trovato nei tipi esistenti\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ccz81NGLHgk0"
      },
      "outputs": [],
      "source": [
        "from torch_frame.data.stats import StatType\n",
        "\n",
        "def merge_text_columns_to_categorical(db, stype_dict):\n",
        "    for table_name in db.table_dict:\n",
        "        table = db.table_dict[table_name]\n",
        "        new_colname = \"merged_text_id\"\n",
        "\n",
        "        # Cerca colonne di tipo test_embedded\n",
        "        col_to_type = stype_dict[table_name]\n",
        "        all_text_cols = [\n",
        "            col for col, stype in col_to_type.items()\n",
        "            if str(stype) == \"text_embedded\"\n",
        "        ]\n",
        "\n",
        "        if not all_text_cols:\n",
        "            continue\n",
        "\n",
        "        # Ordina le colonne alfabeticamente per avere ordine stabile\n",
        "        sorted_cols = sorted(set(all_text_cols))\n",
        "\n",
        "        # Combina i valori riga per riga\n",
        "        merged_col = table.df[sorted_cols].astype(str).apply(lambda row: \"_\".join(row), axis=1)\n",
        "\n",
        "        # Elimina i vecchi tipi dallo stype_dict\n",
        "        for col in sorted_cols:\n",
        "            if col in stype_dict[table_name]:\n",
        "                del stype_dict[table_name][col]\n",
        "\n",
        "        # Elimina le colonne anche dal DataFrame\n",
        "        table.df.drop(columns=sorted_cols, inplace=True, errors=\"ignore\")\n",
        "\n",
        "        # Aggiungi la colonna fusa\n",
        "        table.df[new_colname] = merged_col\n",
        "\n",
        "        # Assegna il tipo corretto\n",
        "        #stype_dict[table_name][new_colname] = stype.categorical\n",
        "        categorical_type = get_stype_enum_with_value(stype_dict, \"categorical\")\n",
        "        stype_dict[table_name][new_colname] = categorical_type\n",
        "\n",
        "\n",
        "    return db, stype_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4FKQN2TzpMC",
        "outputId": "9ae1b7f3-8f40-44f6-fcea-c9b490b5a8f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Loading Database object from /root/.cache/relbench/rel-trial/db...\n",
            "Done in 8.25 seconds.\n"
          ]
        }
      ],
      "source": [
        "dataset = get_dataset(\"rel-trial\", download=True)\n",
        "task = get_task(\"rel-trial\", \"study-adverse\", download=True)\n",
        "\n",
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")\n",
        "\n",
        "out_channels = 1\n",
        "loss_fn = L1Loss()\n",
        "# this is the mae loss and is used when have regressions tasks.\n",
        "tune_metric = \"mae\"\n",
        "higher_is_better = False\n",
        "\n",
        "#seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "root_dir = \"./data\"\n",
        "\n",
        "db = dataset.get_db() #get all tables\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "#this is used to get the stype of the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A4QovFbHsPO"
      },
      "outputs": [],
      "source": [
        "db_nuovo, col_to_stype_dict_nuovo = merge_text_columns_to_categorical(db, col_to_stype_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gvkjcjPr7dB"
      },
      "source": [
        "# Embedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-BBpUrakdwY"
      },
      "outputs": [],
      "source": [
        "# text_embedder_cfg = TextEmbedderConfig(\n",
        "#     text_embedder=LightweightGloveEmbedder(device=device), batch_size=256\n",
        "# )\n",
        "\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    db_nuovo,\n",
        "    col_to_stype_dict=col_to_stype_dict_nuovo,\n",
        "    #text_embedder_cfg=text_embedder_cfg,\n",
        "    text_embedder_cfg = None,\n",
        "    cache_dir=None  # ‚Üê forzatamente disabilitata\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xMIwSVTXXnr"
      },
      "source": [
        "# Graph Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUHVG-g6lM-b"
      },
      "outputs": [],
      "source": [
        "loader_dict = {}\n",
        "\n",
        "for split, table in [\n",
        "    (\"train\", train_table),\n",
        "    (\"val\", val_table),\n",
        "    (\"test\", test_table),\n",
        "]:\n",
        "    table_input = get_node_train_table_input(\n",
        "        table=table,\n",
        "        task=task,\n",
        "    )\n",
        "\n",
        "    entity_table = table_input.nodes[0]\n",
        "\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=[\n",
        "            128 for i in range(2) #################################\n",
        "        ],\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.nodes,\n",
        "        input_time=table_input.time,\n",
        "        transform=table_input.transform,\n",
        "        batch_size=512,\n",
        "        temporal_strategy=\"uniform\",\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=0,\n",
        "        persistent_workers=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDbdc2Iz1Odp"
      },
      "outputs": [],
      "source": [
        "# qui i parametri di train_table, val_table, test_table, task e data sono\n",
        "#parametri globali\n",
        "\n",
        "def loader_dict_fn(batch_size, num_neighbours):\n",
        "    loader_dict = {}\n",
        "\n",
        "    for split, table in [\n",
        "        (\"train\", train_table),\n",
        "        (\"val\", val_table),\n",
        "        (\"test\", test_table),\n",
        "    ]:\n",
        "        table_input = get_node_train_table_input(\n",
        "            table=table,\n",
        "            task=task,\n",
        "        )\n",
        "\n",
        "        loader_dict[split] = NeighborLoader(\n",
        "            data,\n",
        "            num_neighbors=[num_neighbours for _ in range(2)],\n",
        "            time_attr=\"time\",\n",
        "            input_nodes=table_input.nodes,\n",
        "            input_time=table_input.time,\n",
        "            transform=table_input.transform,\n",
        "            batch_size=batch_size,\n",
        "            temporal_strategy=\"uniform\",\n",
        "            shuffle=split == \"train\",\n",
        "            num_workers=0,\n",
        "            persistent_workers=False,\n",
        "        )\n",
        "\n",
        "    return loader_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr7qtFXgr7dE"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3m3jEqClQnw"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData,\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "\n",
        "        self.gnn = HeteroGraphSAGE(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            aggr=aggr,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1, ###################################################\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])\n",
        "\n",
        "    def encode_node_types(self, batch: HeteroData, node_types: List[str]) -> Dict[str, Tensor]:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(seed_time, batch.time_dict, batch.batch_dict)\n",
        "\n",
        "        for node_type in node_types:\n",
        "            if node_type in rel_time_dict:\n",
        "                x_dict[node_type] = x_dict[node_type] + rel_time_dict[node_type]\n",
        "            if node_type in self.embedding_dict:\n",
        "                x_dict[node_type] = x_dict[node_type] + self.embedding_dict[node_type](batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )\n",
        "\n",
        "        return {ntype: x_dict[ntype] for ntype in node_types if ntype in x_dict}\n",
        "\n",
        "\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H1f8MgdYMFQ"
      },
      "source": [
        "# Training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAHRIr15lVs6"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, loader_dict) -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9TjoM9pzkAy",
        "outputId": "78996e8c-e0c0-4b61-d309-04c95bdc642b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_of_adverse_events\n"
          ]
        }
      ],
      "source": [
        "print(task.target_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9RDuFtHVzpP"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pj12I0ip2bU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from typing import Dict, List, Tuple\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "def mask_attributes(batch: HeteroData,\n",
        "                    maskable_attributes: Dict[str, Dict[str, List[str]]],\n",
        "                    p_mask=0.3,\n",
        "                    device=\"cuda\") -> Tuple[HeteroData, Dict]:\n",
        "    \"\"\"\n",
        "    Maschera dinamicamente alcune feature nel batch, e restituisce anche i valori originali mascherati.\n",
        "    \"\"\"\n",
        "    target_values = {}  # per il decoder: quali campi/righe sono stati mascherati e con quali valori originali\n",
        "\n",
        "    for node_type, type_dict in maskable_attributes.items():\n",
        "        if node_type not in batch.node_types:\n",
        "            print(f\"node type {node_type} non trovato, questo grafo ha nodi {batch.node_types}\")\n",
        "            continue\n",
        "\n",
        "        for attr_type, cols in type_dict.items():\n",
        "            for col in cols:\n",
        "\n",
        "                table_columns = []\n",
        "                for stype, cols_in in batch[node_type].tf.col_names_dict.items():\n",
        "                    table_columns.extend(cols_in)\n",
        "\n",
        "                if col not in table_columns:\n",
        "                    print(f\"non abbiamo trovato la colonna {col} nella tabella {node_type}\")\n",
        "                    continue  # Colonna non disponibile nel batch\n",
        "\n",
        "                # --- batch-only: lavora sul DF del batch, non sul DB globale ---\n",
        "                table = batch[node_type].tf.table\n",
        "                df = table.df.copy(deep=True)\n",
        "\n",
        "                # ID globali presenti nel batch e maschera Bernoulli batch-local\n",
        "                local_ids = batch[node_type].n_id.cpu().numpy()\n",
        "                if local_ids.size == 0:\n",
        "                    continue\n",
        "                bern = (torch.rand(len(local_ids), device=device) < p_mask).cpu().numpy()\n",
        "                masked_pos = np.nonzero(bern)[0]  # indici batch-local\n",
        "                if masked_pos.size == 0:\n",
        "                    continue\n",
        "                masked_global = local_ids[masked_pos]\n",
        "\n",
        "                # salva indici batch-local e valori originali\n",
        "                target_values[(node_type, col)] = {\n",
        "                    \"indices\": masked_pos.tolist(),\n",
        "                    \"values\": df.loc[masked_global, col].tolist()\n",
        "                }\n",
        "\n",
        "                # applica sentinel SOLO nel batch\n",
        "                if attr_type == \"categorical\":\n",
        "                    df.loc[masked_global, col] = 0\n",
        "                elif attr_type == \"numerical\":\n",
        "                    df.loc[masked_global, col] = 0.0\n",
        "                else:\n",
        "                    raise ValueError(f\"Tipo non supportato: {attr_type}\")\n",
        "\n",
        "                # scrivi indietro SOLO al batch\n",
        "                table.df = df\n",
        "\n",
        "    return batch, target_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ms2Gu0oOXbB"
      },
      "outputs": [],
      "source": [
        "class MAPDecoder(nn.Module):\n",
        "    def __init__(self, encoder_out_dim: int, hidden_dim: int = 128):\n",
        "        super().__init__()\n",
        "        self.decoder_dict = nn.ModuleDict()\n",
        "        self.encoder_out_dim = encoder_out_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def add_decoder(self, name: str, out_dim: int, task: str):\n",
        "        if task == \"regression\":\n",
        "            self.decoder_dict[name] = nn.Linear(self.encoder_out_dim, out_dim)\n",
        "        elif task == \"classification\":\n",
        "            self.decoder_dict[name] = nn.Linear(self.encoder_out_dim, out_dim)\n",
        "\n",
        "    def forward(self, z_dict, batch, mask_info):\n",
        "        losses = []\n",
        "\n",
        "        for (node_type, col), info in mask_info.items():\n",
        "            z = z_dict[node_type]\n",
        "\n",
        "            # Converto in tensori PyTorch\n",
        "            indices = torch.tensor(info[\"indices\"], device=z.device)\n",
        "            true_vals = torch.tensor(info[\"values\"], device=z.device)\n",
        "\n",
        "            # Estraggo i nodi mascherati\n",
        "            z_masked = z[indices]\n",
        "            decoder = self.decoder_dict[f\"{node_type}__{col}\"]\n",
        "            pred = decoder(z_masked)\n",
        "\n",
        "            if pred.numel() == 0:\n",
        "                continue  # salta se batch vuoto\n",
        "\n",
        "            #lss diversa per regressione o classificazione\n",
        "            if true_vals.dtype in [torch.float, torch.float32, torch.float64]:\n",
        "                loss = F.mse_loss(pred.squeeze(), true_vals.float())\n",
        "            else:\n",
        "                loss = F.cross_entropy(pred, true_vals.long())\n",
        "\n",
        "            losses.append(loss)\n",
        "\n",
        "        if len(losses) == 0:\n",
        "            return torch.tensor(0.0, requires_grad=True, device=z.device)\n",
        "\n",
        "        return sum(losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUS7C9r-tTaq"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def extract_categorical_values_from_db(db, maskable_attributes):\n",
        "    value_dict = defaultdict(lambda: defaultdict(set))\n",
        "\n",
        "    for node_type, type_dict in maskable_attributes.items():\n",
        "        if node_type not in db.table_dict:\n",
        "            print(f\"Tabella {node_type} non trovata nel db.\")\n",
        "            continue\n",
        "\n",
        "        table = db.table_dict[node_type]\n",
        "        df = table.df\n",
        "\n",
        "        for col in type_dict.get(\"categorical\", []):\n",
        "            if col not in df.columns:\n",
        "                print(f\"Colonna {col} non trovata nella tabella {node_type}\")\n",
        "                continue\n",
        "\n",
        "            unique_vals = df[col].dropna().unique()\n",
        "            value_dict[node_type][col].update(unique_vals)\n",
        "\n",
        "    # Converte in liste ordinate per sicurezza\n",
        "    value_dict_final = {\n",
        "        node: {col: sorted(list(vals)) for col, vals in col_dict.items()}\n",
        "        for node, col_dict in value_dict.items()\n",
        "    }\n",
        "\n",
        "    return value_dict_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqrkmEeMU2bP"
      },
      "outputs": [],
      "source": [
        "# cat_values = extract_categorical_values_from_db(db, maskable_attributes)\n",
        "# print(cat_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4PNZBIltupq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_map(model, loader_dict, maskable_attributes, encoder_out_dim: int, device: str, cat_values ,epochs: int = 20):\n",
        "    model.train()\n",
        "    decoder = MAPDecoder(encoder_out_dim)\n",
        "\n",
        "    #Inizializzazione decoder per ogni colonna\n",
        "    for node_type, type_dict in maskable_attributes.items():\n",
        "      for col in type_dict.get(\"categorical\", []):\n",
        "          try:\n",
        "              out_dim = len(cat_values[node_type][col])#qua prendo il numero di possibili valori\n",
        "              decoder.add_decoder(f\"{node_type}__{col}\", out_dim=out_dim, task=\"classification\")\n",
        "              #print(f\"Aggiunto decoder per {node_type}__{col} con out_dim={out_dim}\")\n",
        "          except KeyError:\n",
        "              print(f\"Nessun valore trovato per {node_type}__{col}, decoder non aggiunto\")\n",
        "\n",
        "      for col in type_dict.get(\"numerical\", []):\n",
        "          decoder.add_decoder(f\"{node_type}__{col}\", out_dim=1, task=\"regression\")\n",
        "\n",
        "\n",
        "    decoder.to(device)\n",
        "    optimizer = torch.optim.Adam(list(model.parameters()) + list(decoder.parameters()), lr=1e-3)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        total_loss = 0.0\n",
        "        for batch in loader_dict[\"train\"]:\n",
        "            batch = batch.to(device)\n",
        "            batch, mask_info = mask_attributes(batch, maskable_attributes)\n",
        "            z_dict = model.encode_node_types(batch, node_types=list(maskable_attributes.keys()))\n",
        "\n",
        "            loss = decoder(z_dict, batch, mask_info)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"[MAP] Epoch {epoch:02d} | Loss: {total_loss:.4f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBIUhpUuPCiD"
      },
      "outputs": [],
      "source": [
        "# for batch in loader_dict[\"train\"]:\n",
        "#     batch = batch.to(device)\n",
        "#     batch, mask_info = mask_attributes(batch, maskable_attributes)\n",
        "#     print(mask_info)\n",
        "#     for (node_type, col), info in mask_info.items():\n",
        "#       #z = z_dict[node_type]\n",
        "\n",
        "#             # Converto in tensori PyTorch\n",
        "#       indices = torch.tensor(info[\"indices\"], device=\"cuda\")\n",
        "#       #true_vals = torch.tensor(info[\"values\"], device=\"cuda\")\n",
        "#       raw_vals = info[\"values\"]\n",
        "\n",
        "#       if any(isinstance(v, str) for v in raw_vals):\n",
        "#           try:\n",
        "#               classes = mask_info[node_type][col]\n",
        "#               str_to_idx = {v: i for i, v in enumerate(classes)}\n",
        "#               idx_vals = [str_to_idx[val] if isinstance(val, str) else 0 for val in raw_vals]  # fallback 0\n",
        "#               true_vals = torch.tensor(idx_vals, device=z.device)\n",
        "#           except KeyError:\n",
        "\n",
        "#               continue\n",
        "\n",
        "#       else:\n",
        "#           try:\n",
        "#               float_vals = [float(v) if isinstance(v, (int, float, str)) and str(v).strip() != \"\" else 0.0 for v in raw_vals]\n",
        "#               true_vals = torch.tensor(float_vals, device=z.device)\n",
        "#           except Exception as e:\n",
        "#               print(f\"[‚ö†Ô∏è] Errore nella conversione numerica per {node_type}.{col}: {e}\")\n",
        "#               continue\n",
        "\n",
        "#       print(f\"indices {indices}\")\n",
        "#       print(f\"true values{true_vals} \")\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOAVX_EaOjh6"
      },
      "outputs": [],
      "source": [
        "# print(f\"{cat_values}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qFUQmyRRYvN"
      },
      "outputs": [],
      "source": [
        "loader_dict = loader_dict_fn(batch_size=512, num_neighbours=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8tsUJRVuih3"
      },
      "outputs": [],
      "source": [
        "# train_map(model, loader_dict, maskable_attributes, encoder_out_dim=128, device=device, cat_values = cat_values, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHVNJxzTdrdk"
      },
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=2,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"max\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)\n",
        "\n",
        "# maskable_attributes = {\n",
        "#     \"studies\": {\n",
        "#         \"categorical\": [\"study_type\", \"phase\", \"is_fda_regulated_drug\", \"is_fda_regulated_device\"],\n",
        "#         \"numerical\": [\"enrollment\"]\n",
        "#     },\n",
        "#     \"outcomes\": {\n",
        "#         \"categorical\": [\"outcome_type\"]\n",
        "#     },\n",
        "#     \"reported_event_totals\": {\n",
        "#         \"categorical\": [\"event_type\", \"classification\"]\n",
        "#     }\n",
        "# }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhpXz1v5eA1o"
      },
      "outputs": [],
      "source": [
        "def evaluate_performance(pred: np.ndarray, target_table, metrics) -> dict:\n",
        "    \"\"\"Custom evaluation function to replace task.evaluate.\"\"\"\n",
        "    target = target_table.df[task.target_col].to_numpy()\n",
        "\n",
        "    if len(pred) != len(target):\n",
        "        raise ValueError(\n",
        "            f\"The length of pred and target must be the same (got \"\n",
        "            f\"{len(pred)} and {len(target)}, respectively).\"\n",
        "        )\n",
        "\n",
        "    results = {}\n",
        "    for metric_fn in metrics:\n",
        "        if metric_fn.__name__ == \"rmse\":\n",
        "            results[\"rmse\"] = np.sqrt(np.mean((target - pred)**2))\n",
        "        else:\n",
        "            results[metric_fn.__name__] = metric_fn(target, pred)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwEpAxQbeFj4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_on_train_during_training() -> float:\n",
        "    model.eval()\n",
        "    pred_list, target_list = [], []\n",
        "\n",
        "    for batch in loader_dict[\"train\"]:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(batch, task.entity_table)\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "        target_list.append(batch[task.entity_table].y.detach().cpu())\n",
        "\n",
        "    pred_all = torch.cat(pred_list, dim=0).numpy()\n",
        "    target_all = torch.cat(target_list, dim=0).numpy()\n",
        "\n",
        "    mae = np.mean(np.abs(pred_all - target_all))\n",
        "    return mae\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "gat6rTNcd1r0",
        "outputId": "f958c4c3-7682-4b31-f6e7-101d7569098f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 85/85 [00:18<00:00,  4.64it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'evaluate_on_full_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-718376a97e11>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrain_mae_preciso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_on_full_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate_on_full_train' is not defined"
          ]
        }
      ],
      "source": [
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=2,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"max\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=0.0005,\n",
        "    weight_decay=0\n",
        ")\n",
        "\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "loader_dict = loader_dict_fn(batch_size=512, num_neighbours=256)\n",
        "\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "state_dict = None\n",
        "test_table = task.get_table(\"test\", mask_input_cols=False)\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "best_test_metric = -math.inf if higher_is_better else math.inf\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(model, optimizer, loader_dict=loader_dict)\n",
        "\n",
        "    train_pred = test(model, loader_dict[\"train\"])\n",
        "    train_metrics = evaluate_performance(train_pred, train_table, task.metrics)\n",
        "    train_mae_preciso = evaluate_on_full_train(model, loader_dict[\"train\"])\n",
        "\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    val_metrics = evaluate_performance(val_pred, val_table, task.metrics)\n",
        "\n",
        "    test_pred = test(model, loader_dict[\"test\"])\n",
        "    test_metrics = evaluate_performance(test_pred, test_table, task.metrics)\n",
        "\n",
        "    scheduler.step(val_metrics[tune_metric])\n",
        "\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    #test:\n",
        "    if (higher_is_better and test_metrics[tune_metric] > best_test_metric) or (\n",
        "            not higher_is_better and test_metrics[tune_metric] < best_test_metric\n",
        "    ):\n",
        "        best_test_metric = test_metrics[tune_metric]\n",
        "        state_dict_test = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "    print(f\"Epoch: {epoch:02d}, Train {tune_metric}: {train_mae_preciso:.2f}, Validation {tune_metric}: {val_metrics[tune_metric]:.2f}, Test {tune_metric}: {test_metrics[tune_metric]:.2f}, LR: {current_lr:.6f}\")\n",
        "\n",
        "    #early_stopping(val_metrics[tune_metric], model)\n",
        "\n",
        "    # if early_stopping.early_stop:\n",
        "    #     print(f\"Early stopping triggered at epoch {epoch}\")\n",
        "    #     break\n",
        "print(f\"best validation results: {best_val_metric}\")\n",
        "print(f\"best test results: {best_test_metric}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4D3ONst6S0pI",
        "1gvkjcjPr7dB",
        "6xMIwSVTXXnr",
        "Nr7qtFXgr7dE"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
