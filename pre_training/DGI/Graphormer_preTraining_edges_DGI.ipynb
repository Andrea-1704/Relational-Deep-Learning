{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea-1704/Pytorch_Geometric_tutorial/blob/main/train_model_baseline_f1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiCB_SVeanwO"
      },
      "source": [
        "In questo notebook vorrei provare a mettere assieme sia il pre training basato su archi che quello basato su contrastive learning (DGI) per provare a vedere se la combinazione di questi due pre training tasks aiuti effettivamente il modello originale sul downstream task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {
        "id": "zNziUzq9nTdU"
      },
      "outputs": [],
      "source": [
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "\n",
        "# !pip install pytorch_frame[full]==1.2.2\n",
        "# !pip install relbench[full]==1.0.0\n",
        "# !pip uninstall -y pyg_lib torch  # Uninstall current versions\n",
        "# !pip install torch==2.6.0  # Reinstall your desired PyTorch version\n",
        "# !pip install --no-cache-dir git+https://github.com/pyg-team/pyg-lib.git # Install pyg-lib; --no-cache-dir ensures a fresh install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8VinWw-anwR"
      },
      "source": [
        "New libraries to run on colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "cTB7Q6qQanwR"
      },
      "outputs": [],
      "source": [
        "# !pip install torch==2.6.0+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "\n",
        "# !pip install pytorch_frame[full]==1.2.2\n",
        "# !pip install relbench[full]==1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "F454ta1Zg0Oq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.tasks import get_task\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import torch_geometric\n",
        "import torch_frame\n",
        "from torch_geometric.seed import seed_everything\n",
        "from relbench.modeling.utils import get_stype_proposal\n",
        "from collections import defaultdict\n",
        "import requests\n",
        "from io import StringIO\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "import pyg_lib\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#per lo scheduler\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import Linear\n",
        "from torch_geometric.utils import softmax\n",
        "from torch_geometric.utils import degree\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTytIKXvanwT"
      },
      "source": [
        "# Dataset and task creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DWB-Kf6nl2y",
        "outputId": "66be9a84-ecd8-4373-f068-167df926c213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "dataset = get_dataset(\"rel-f1\", download=True)\n",
        "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
        "\n",
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")\n",
        "\n",
        "out_channels = 1\n",
        "# one because we are estimating one single value.\n",
        "loss_fn = L1Loss()\n",
        "# this is the mae loss and is used when have regressions tasks.\n",
        "tune_metric = \"mae\"\n",
        "higher_is_better = False\n",
        "\n",
        "seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "root_dir = \"./data\"\n",
        "\n",
        "db = dataset.get_db()\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "#this is used to get the stype of the columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVsgNYpuanwU"
      },
      "source": [
        "# Embedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {
        "id": "QQHYmgIxkX1j"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from typing import List, Optional\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from torch import Tensor\n",
        "\n",
        "\n",
        "# class GloveTextEmbedding:\n",
        "#     def __init__(self, device: Optional[torch.device\n",
        "#                                        ] = None):\n",
        "#         self.model = SentenceTransformer(\n",
        "#             \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "#             device=device,\n",
        "#         )\n",
        "\n",
        "#     def __call__(self, sentences: List[str]) -> Tensor:\n",
        "#         return torch.from_numpy(self.model.encode(sentences))\n",
        "\n",
        "\n",
        "class LightweightGloveEmbedder:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device\n",
        "        self.embeddings = defaultdict(lambda: np.zeros(300))\n",
        "        self._load_embeddings()\n",
        "\n",
        "    def _load_embeddings(self):\n",
        "        try:\n",
        "            #(senza bisogno di estrarre zip\n",
        "            url = \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt\"\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            for line in StringIO(response.text):\n",
        "                parts = line.split()\n",
        "                word = parts[0]\n",
        "                vector = np.array(parts[1:], dtype=np.float32)\n",
        "                self.embeddings[word] = vector\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Couldn't load GloVe embeddings ({str(e)}). Using zero vectors.\")\n",
        "\n",
        "    def __call__(self, sentences):\n",
        "        results = []\n",
        "        for text in sentences:\n",
        "            words = text.lower().split()\n",
        "            vectors = [self.embeddings[w] for w in words if w in self.embeddings]\n",
        "            if vectors:\n",
        "                avg_vector = np.mean(vectors, axis=0)\n",
        "            else:\n",
        "                avg_vector = np.zeros(300)\n",
        "            results.append(avg_vector)\n",
        "\n",
        "        tensor = torch.tensor(np.array(results), dtype=torch.float32)\n",
        "        return tensor.to(self.device) if self.device else tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-BBpUrakdwY",
        "outputId": "76bd6355-aa1b-4ff2-9060-2c68c7acb269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Couldn't load GloVe embeddings (404 Client Error: Not Found for url: https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt). Using zero vectors.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n"
          ]
        }
      ],
      "source": [
        "text_embedder_cfg = TextEmbedderConfig(\n",
        "    text_embedder=LightweightGloveEmbedder(device=device), batch_size=256\n",
        ")\n",
        "\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    #Solution if not working: !pip install --upgrade torch torchvision transformers\n",
        "    db,\n",
        "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
        "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
        "    cache_dir=os.path.join(\n",
        "        root_dir, f\"rel-f1_materialized_cache\"\n",
        "    ),  # store materialized graph for convenience\n",
        ")# create a graph how relbench requires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "HUHVG-g6lM-b"
      },
      "outputs": [],
      "source": [
        "loader_dict = {}\n",
        "\n",
        "for split, table in [\n",
        "    (\"train\", train_table),\n",
        "    (\"val\", val_table),\n",
        "    (\"test\", test_table),\n",
        "]:\n",
        "    table_input = get_node_train_table_input(\n",
        "        table=table,\n",
        "        task=task,\n",
        "    )#notice that table_input is an object with three elements: nodes, time and transform.\n",
        "    #nodes contains the input nodes\n",
        "    #time contains the time for each node\n",
        "    #transform is the tranformation to be applied to nodes\n",
        "    entity_table = table_input.nodes[0]\n",
        "    #we need to populate the loader_dict with three elements: \"train\", \"val\", and \"test\".\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=[\n",
        "            128 for i in range(2)\n",
        "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.nodes,\n",
        "        input_time=table_input.time,\n",
        "        transform=table_input.transform,\n",
        "        batch_size=512,\n",
        "        temporal_strategy=\"uniform\",\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=0,\n",
        "        persistent_workers=False,\n",
        "    )#this is the loader for grapg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNecfPt3anwW"
      },
      "source": [
        "Nota che ogni oggetto \"batch\" rappresenta un dizionario in cui le chiavi rappresentano i tipi di nodi oppure i tipi di archi e contengono gli embedding del nodo opppure l'edge index dell'arco (vale a dire un tensore di dimensione 2xnumero di edge, ovvero la lista dei nodi di tipo sorgente che presdentano una relazione di quel tipo con i nodi di tipo destinazione, ovvero quelli della seconda lista)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLTbwru5f3lN"
      },
      "source": [
        "# Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "wu1mIK-Mf5Zv"
      },
      "outputs": [],
      "source": [
        "def plot_validation_metrics(metric_histories, model_names=None, metric_name=\"MAE\", informationsTitle=\"\"):\n",
        "    \"\"\"\n",
        "    Plotta l'andamento del metric_name per più modelli nel tempo.\n",
        "\n",
        "    Args:\n",
        "        metric_histories (list of lists): Lista di liste, ognuna rappresenta i valori di metriche per un modello.\n",
        "        model_names (list of str): Nomi dei modelli (opzionale).\n",
        "        metric_name (str): Nome della metrica da visualizzare.\n",
        "        informationsTitle (str): info aggiungitive da mettere nel titolo (conf generale dei parametri ecc).\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(9, 5))\n",
        "\n",
        "    if model_names is None:\n",
        "        model_names = [f\"Model {i+1}\" for i in range(len(metric_histories))]\n",
        "\n",
        "    for metrics, name in zip(metric_histories, model_names):\n",
        "        plt.plot(metrics, marker='o', label=f'{name} {metric_name}')\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.title(f\"{metric_name} over Epochs for Multiple Models {informationsTitle}\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7DiIz69anwW"
      },
      "source": [
        "# Pre-training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ5NA4RDxydM"
      },
      "source": [
        "##DGI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDHxR9BV5fW0"
      },
      "source": [
        "Disciminator, calcola semplicemente il prodotto scalare tra z e summary (embedding globale del grafo di partenza) e predice se è vero o falso.\n",
        "\n",
        "L'obiettivo di questo pre training è quello di costruire un **sunmmary** dell'intero grafo, che in questo caso è calcolato come media degli embedding dei suoi nodi. Successivamente cerchiamo di massimizzare la somiglianza (similarity) tra gli embeddings dei nodi effettivamente presenti dentro il grafo (detti **nodi positivi**) e minimizzare quella con nodi \"corrotti\", ovvero nodi modificati appositamente (detti **nodi negativi**). Speriamo in questo modo che i parametri del modello iniziale (prima di cominciare il training vero e proprio) contengano già informazioni rilevanti sul grafo, ovvero siano in grado di riconoscere una certa struttura degli embeddings dei nodi.\n",
        "\n",
        "In questo modo quindi speriamo che i pesi del modello iniziale non siano \"casuali\" ma contengono già una certa sematica sui nodi, ovvero che gli embeddings dei nodi contengano già rilevanti informazioni sulla struttura del grafo, la \"logica\" dei nodi e le relazioni rilevanti tra i nodi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "vF4LrxL55fW1"
      },
      "outputs": [],
      "source": [
        "class DGIHead(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.Tensor(hidden_dim, hidden_dim))\n",
        "        torch.nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, x_dict, corrupted_x_dict, summary):\n",
        "        loss = 0\n",
        "        for node_type in x_dict:\n",
        "            z = x_dict[node_type]                     # [N, hidden]\n",
        "            #qui prendiamo la struttura [num_nodes, features] positivi\n",
        "            z_corrupt = corrupted_x_dict[node_type]   # [N, hidden]\n",
        "            #struttura [num_nodes, features] negativi.\n",
        "            if z.shape[0] == 0:\n",
        "              continue\n",
        "            #print(\"x corrotto: \", z_corrupt)\n",
        "\n",
        "            pos = torch.matmul(z, self.weight)        # [N, hidden]\n",
        "            neg = torch.matmul(z_corrupt, self.weight)# [N, hidden]\n",
        "\n",
        "            summary_proj = summary.t()                # [hidden, 1]\n",
        "            #andiamo a trasporre la summary del grafo.\n",
        "\n",
        "            pos_score = torch.matmul(pos, summary_proj).squeeze()  # [N]\n",
        "            #usiamo come metrica di similarity il prodotto.\n",
        "            neg_score = torch.matmul(neg, summary_proj).squeeze()  # [N]\n",
        "\n",
        "            #print(\"il positive score è: \", pos_score)-> qui è già nan!\n",
        "\n",
        "            pos_loss = -torch.log(torch.sigmoid(pos_score) + 1e-15).mean()\n",
        "            #print(\"il positive score dopo la log è: \", pos_loss)\n",
        "\n",
        "            neg_loss = -torch.log(1 - torch.sigmoid(neg_score) + 1e-15).mean()\n",
        "\n",
        "            loss += pos_loss + neg_loss\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCT5ROKCbw8i"
      },
      "source": [
        "Per capire la funzione di forward ricorda che x_dict è il dizionario originale quello, ovvero, che contiene gli emebeddings effettivi per i tipi di nodi. corrupted_x_dict è un dizionario che segue la stessa struttura ma che contiene gli embeddings negativi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VITfV5h_nU2"
      },
      "source": [
        "Qui sotto definiamo una funzione che calcoli una sintesi dell'intero grafo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "dFJ1Al-eP2aJ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_summary(x_dict):\n",
        "    summary_dict = {}\n",
        "    for k, z in x_dict.items():\n",
        "        #se nonm abbiamo nodi di quel tipo escludi\n",
        "        if z.numel() == 0:\n",
        "            summary_dict[k] = torch.zeros(z.shape[1], device=z.device)\n",
        "        else:\n",
        "            summary_dict[k] = torch.tanh(z.mean(dim=0))\n",
        "    return summary_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXbJemA-_tSk"
      },
      "source": [
        "Di seguito si mostra l'implementazione di una funzione che prende come parametro un HeteroGraph e restituisce un altro HeteroGrapf in cui i nodi sono stati corrotti, ovvero mescoliamo in modo randomico le features dei nodi: in pratica un tipo di nodo x riceve casualmente le features del nodo y, per esempoio alla tabella delle corse sono dati deglki embeddings della tabella di costruzioni (chiaramente archi rimangono invariati).\n",
        "\n",
        "Lo vorremmo fare direttamente per le x, ovvero le features dei tipi di nodi. Tuttavia questo nel batch non è direttamente presente, ma è presente n_id che associa, ordinatamente, ad ogni nodo un id del nodo aa cui fa riferiemnto e quindi successivamente da quell'id si recuperano i suoi embeddings. Possiamo quindi modificare semplicemente l'ordine di n_id per cambiare i nodi di partenza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "id": "zE1U-X2SP3tc"
      },
      "outputs": [],
      "source": [
        "def corrupt_features(batch: HeteroData) -> HeteroData:\n",
        "    corrupted = copy.deepcopy(batch)\n",
        "    #costruisco una clone del batch di grafo per evitare di modificare\n",
        "    #il grafo originale\n",
        "    for node_type in corrupted.node_types:\n",
        "        #print(corrupted[node_type])\n",
        "        #if hasattr(corrupted[node_type], \"n_id\"):\n",
        "        # Use embeddings, permute n_ids\n",
        "        n_id = corrupted[node_type].n_id\n",
        "        perm = torch.randperm(n_id.size(0))\n",
        "        corrupted[node_type].n_id = n_id[perm]\n",
        "    return corrupted\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2co0JIsc5fW2"
      },
      "source": [
        "Funzione che effettua il pre training per qualche epoca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "id": "dkGCazfH5fW2"
      },
      "outputs": [],
      "source": [
        "def train_dgi(model, discriminator, optimizer, loader, device, entity_table, epochs=20):\n",
        "    model.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        for batch in pbar:\n",
        "            batch = batch.to(device)\n",
        "\n",
        "            # Corrupt the batch\n",
        "            corrupted_batch = corrupt_features(batch)\n",
        "            corrupted_batch = corrupted_batch.to(device)\n",
        "\n",
        "            # Get positive and negative embeddings + summary\n",
        "            z_dict, summary = model.pretrain_dgi_forward(batch, entity_table=entity_table)\n",
        "            corrupted_z_dict, _ = model.pretrain_dgi_forward(corrupted_batch, entity_table=entity_table)\n",
        "\n",
        "            # Compute DGI loss\n",
        "            loss = discriminator(z_dict, corrupted_z_dict, summary)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_postfix({\"DGI Loss\": loss.item()})\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Average DGI Loss: {epoch_loss / len(loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqxb0JVWx1A-"
      },
      "source": [
        "##Edge pre training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "UUPvvU4Ix6MU"
      },
      "outputs": [],
      "source": [
        "def sample_edge_prediction_batch(batch: HeteroData, edge_type, neg_ratio=1.0):\n",
        "\n",
        "    #prendiamo gli archi positivi, ovvero quelli che esistono davvero:\n",
        "    pos_edge_index = batch[edge_type].edge_index\n",
        "    num_pos = pos_edge_index.size(1)\n",
        "\n",
        "    if num_pos == 0:\n",
        "        # Se non ci sono archi positivi, salta questo batch\n",
        "        raise ValueError(f\"No positive edges found in batch for edge_type {edge_type}\")\n",
        "\n",
        "    #prendiamo ora i sample negativi: archi che non esistono nel grafo\n",
        "    src, dst = pos_edge_index[0], pos_edge_index[1]\n",
        "    neg_src = src[torch.randint(0, src.size(0), (int(num_pos * neg_ratio),))]\n",
        "    neg_dst = dst[torch.randint(0, dst.size(0), (int(num_pos * neg_ratio),))]\n",
        "    #nota potremmo averere come negativi degli archi che in realtà sono positivi\n",
        "    pos_labels = torch.ones(num_pos, device=src.device)\n",
        "    neg_labels = torch.zeros(neg_src.size(0), device=src.device)\n",
        "\n",
        "    edge_src = torch.cat([src, neg_src], dim=0)\n",
        "    edge_dst = torch.cat([dst, neg_dst], dim=0)\n",
        "    labels = torch.cat([pos_labels, neg_labels], dim=0)\n",
        "\n",
        "    return edge_src, edge_dst, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US9sDBdbyLCl"
      },
      "source": [
        "Adeso andiamo ad implementare un modello che verrà utilizzato per effettuare il processo di **edge prediction**, ovvero il pre training al fine di inizializzare in maniera \"intelligente\" i pesi della rete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghPvZWqHyLw2"
      },
      "source": [
        "Adesso necessitiamo di definire un metodo che effettui il processo di pre training, sarebbe quindi come definire un codice alternativo di training per un task differente (quello di link prediction) questo modello verà poi raffinato tramite un processo di trainig per il downstream task (quello effettivo di relbench)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "f8ONJh9WyPsU"
      },
      "outputs": [],
      "source": [
        "def pretrain_edge_prediction(model, loader, edge_type, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "    #non lavora male per il task che dobbiamo effettuare sugli archi visto\n",
        "    #che effettuiamo un task di predizione binaria (link presente o meno)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits, labels = model(batch, edge_type)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss / len(loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K82UQwDgfkEX"
      },
      "source": [
        "## Graphormer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "PoAmtoPsanwZ"
      },
      "outputs": [],
      "source": [
        "_spatial_bias_cache = None\n",
        "_node_offset_cache = None\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def compute_spatial_bias(edge_index_dict, x_dict):\n",
        "    global _spatial_bias_cache, _node_offset_cache\n",
        "    if _spatial_bias_cache is not None:\n",
        "        return _spatial_bias_cache, _node_offset_cache\n",
        "    #creiamo un grafo diretto con Networkx\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    node_offset = {}\n",
        "    curr_offset = 0\n",
        "\n",
        "    #aggiungiamo i nodi con offset per mantenere indici globali univoci\n",
        "    for node_type, x in x_dict.items():\n",
        "        node_offset[node_type] = curr_offset\n",
        "        for i in range(x.size(0)):\n",
        "            G.add_node(curr_offset + i, type=node_type)\n",
        "        curr_offset += x.size(0)\n",
        "\n",
        "    #Aggiungiamo gli archi con offset\n",
        "    for (src_type, _, dst_type), edge_index in edge_index_dict.items():\n",
        "        src_offset = node_offset[src_type]\n",
        "        dst_offset = node_offset[dst_type]\n",
        "        src, dst = edge_index\n",
        "        for s, d in zip(src.tolist(), dst.tolist()):\n",
        "            G.add_edge(src_offset + s, dst_offset + d)\n",
        "\n",
        "\n",
        "    spatial_bias = defaultdict(lambda: -1)\n",
        "\n",
        "\n",
        "\n",
        "    for node in G.nodes():\n",
        "        lengths = nx.single_source_dijkstra_path_length(G, node)\n",
        "        for target, dist in lengths.items():\n",
        "            spatial_bias[(node, target)] = dist\n",
        "        #quelli non raggiungibili li lasciamo con default value, ovvero -1\n",
        "\n",
        "    _spatial_bias_cache = spatial_bias\n",
        "    _node_offset_cache = node_offset\n",
        "\n",
        "    return spatial_bias, node_offset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "rN-8kKQianwa"
      },
      "outputs": [],
      "source": [
        "class HeteroGraphormerLayerComplete(nn.Module):\n",
        "    def __init__(self, channels, edge_types, device, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.num_heads = num_heads\n",
        "        self.channels = channels\n",
        "        self.head_dim = channels // num_heads\n",
        "\n",
        "        assert self.channels % num_heads == 0, \"channels must be divisible by num_heads\"\n",
        "\n",
        "        self.q_lin = Linear(channels, channels)\n",
        "        self.k_lin = Linear(channels, channels)\n",
        "        self.v_lin = Linear(channels, channels)\n",
        "        self.out_lin = Linear(channels, channels)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(channels)\n",
        "\n",
        "        # Registriamo i bias per ogni tipo di edge nel __init__\n",
        "        self.edge_type_bias = nn.ParameterDict({\n",
        "            \"__\".join(edge_type): nn.Parameter(torch.randn(1))\n",
        "            for edge_type in edge_types\n",
        "        })\n",
        "\n",
        "    def compute_total_degrees(self, x_dict, edge_index_dict):\n",
        "        device = self.device\n",
        "        in_deg = defaultdict(lambda: torch.zeros(0, device=device))\n",
        "        out_deg = defaultdict(lambda: torch.zeros(0, device=device))\n",
        "        for edge_type, edge_index in edge_index_dict.items():\n",
        "            src_type, _, dst_type = edge_type\n",
        "            src = edge_index[0]\n",
        "            dst = edge_index[1]\n",
        "\n",
        "            num_src = x_dict[src_type].size(0)\n",
        "            num_dst = x_dict[dst_type].size(0)\n",
        "\n",
        "            if out_deg[src_type].numel() == 0:\n",
        "                out_deg[src_type] = torch.zeros(num_src, device=device)\n",
        "            if in_deg[dst_type].numel() == 0:\n",
        "                in_deg[dst_type] = torch.zeros(num_dst, device=device)\n",
        "\n",
        "            out_deg[src_type] += degree(src, num_nodes=num_src)\n",
        "            in_deg[dst_type]  += degree(dst, num_nodes=num_dst)\n",
        "\n",
        "        total_deg = {\n",
        "            node_type: in_deg[node_type] + out_deg[node_type]\n",
        "            for node_type in x_dict\n",
        "        }\n",
        "\n",
        "        return total_deg\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        #print(edge_index_dict)\n",
        "        self.spatial_bias, self.node_offset = compute_spatial_bias(edge_index_dict, x_dict)\n",
        "\n",
        "        out_dict = {k: torch.zeros_like(v) for k, v in x_dict.items()}\n",
        "        for edge_type, edge_index in edge_index_dict.items():\n",
        "            src_type, _, dst_type = edge_type\n",
        "            x_src, x_dst = x_dict[src_type], x_dict[dst_type]\n",
        "\n",
        "            #src, dst = edge_index\n",
        "            src = edge_index[0]\n",
        "            dst = edge_index[1]\n",
        "\n",
        "            Q = self.q_lin(x_dst).view(-1, self.num_heads, self.head_dim)\n",
        "            K = self.k_lin(x_src).view(-1, self.num_heads, self.head_dim)\n",
        "            V = self.v_lin(x_src).view(-1, self.num_heads, self.head_dim)\n",
        "\n",
        "            attn_scores = (Q[dst] * K[src]).sum(dim=-1) / self.head_dim**0.5\n",
        "            src_offset = self.node_offset[src_type]\n",
        "            dst_offset = self.node_offset[dst_type]\n",
        "\n",
        "            spatial_bias_vals = []\n",
        "            for s, d in zip(src.tolist(), dst.tolist()):\n",
        "                global_s = src_offset + s\n",
        "                global_d = dst_offset + d\n",
        "                dist = self.spatial_bias.get((global_d, global_s), -1.0)\n",
        "                spatial_bias_vals.append(dist)\n",
        "\n",
        "            spatial_bias_tensor = torch.tensor(spatial_bias_vals, dtype=torch.float, device=self.device)\n",
        "            attn_scores = attn_scores + spatial_bias_tensor.unsqueeze(-1)  # broadcast su heads\n",
        "\n",
        "\n",
        "            bias_name = \"__\".join(edge_type)\n",
        "            attn_scores = attn_scores + self.edge_type_bias[bias_name]\n",
        "\n",
        "            attn_weights = softmax(attn_scores, dst)\n",
        "            attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "            out = V[src] * attn_weights.unsqueeze(-1)\n",
        "            out = out.view(-1, self.channels)\n",
        "\n",
        "            out_dict[dst_type].index_add_(0, dst, out)\n",
        "\n",
        "        #calcolo della degree centrality\n",
        "\n",
        "        total_deg = self.compute_total_degrees(x_dict, edge_index_dict)\n",
        "\n",
        "\n",
        "        for node_type in out_dict:\n",
        "\n",
        "            degree_embed = total_deg[node_type].view(-1, 1)                                                                                  # Assicurati che sia una colonna\n",
        "            degree_embed = degree_embed.expand(-1, self.channels)                                                                            # Espandi lungo la dimensione dei canali\n",
        "\n",
        "\n",
        "            out_dict[node_type] = out_dict[node_type] + degree_embed\n",
        "\n",
        "\n",
        "        for node_type in out_dict:\n",
        "            out_dict[node_type] = self.norm(out_dict[node_type] + x_dict[node_type])\n",
        "\n",
        "        return out_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "id": "xz8Y3N_kanwa"
      },
      "outputs": [],
      "source": [
        "class HeteroGraphormer(torch.nn.Module):\n",
        "    def __init__(self, node_types, edge_types, channels, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.ModuleList([\n",
        "            HeteroGraphormerLayerComplete(channels, edge_types, device) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, *args, **kwargs):\n",
        "        for layer in self.layers:\n",
        "            x_dict = layer(x_dict, edge_index_dict)\n",
        "        return x_dict\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for layer in self.layers:\n",
        "            if hasattr(layer, \"reset_parameters\"):\n",
        "                layer.reset_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NVV8lcwfqrc"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "u3m3jEqClQnw"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData, #notice that \"data2 is the graph we created with function make_pkey_fkey_graph\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        # List of node types to add shallow embeddings to input\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        # ID awareness\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "        self.gnn = HeteroGraphormer(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,#one, since we are doing regression\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "\n",
        "\n",
        "    def pretrain_dgi_forward(self, batch: HeteroData, entity_table: NodeType):\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        # Costruiamo x_dict\n",
        "\n",
        "        if self.id_awareness_emb is not None:\n",
        "            for node_type in x_dict:\n",
        "                x_dict[node_type] += self.id_awareness_emb.weight\n",
        "\n",
        "        if hasattr(batch[entity_table], \"seed_time\"):\n",
        "            rel_time_dict = self.temporal_encoder(\n",
        "                batch[entity_table].seed_time,\n",
        "                batch.time_dict,\n",
        "                batch.batch_dict\n",
        "            )\n",
        "            for node_type, rel_time in rel_time_dict.items():\n",
        "                x_dict[node_type] += rel_time\n",
        "        # Aggiungiamo il temporal encoding se presente\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] += embedding(batch[node_type].n_id)\n",
        "        # Aggiungiamo gli shallow embeddings per i nodi che lo hanno abilitato\n",
        "\n",
        "        z_dict = self.gnn(x_dict, batch.edge_index_dict)\n",
        "        # Passiamo alla GNN e riceviamo gli embeddings aggiornati (z_dict)\n",
        "\n",
        "        # ⛔️ Gestione dei tensori vuoti per evitare errori nel summary\n",
        "        valid_z_list = []\n",
        "        for node_type, z in z_dict.items():\n",
        "            if z.size(0) != 0:\n",
        "\n",
        "                valid_z_list.append(z.mean(dim=0, keepdim=True))\n",
        "\n",
        "        # Se nessun nodo ha embeddings validi, ritorniamo None\n",
        "        if len(valid_z_list) == 0:\n",
        "            #print(\"[DEBUG] Nessun embedding valido per il summary, ritorno None.\")\n",
        "            return None, None\n",
        "\n",
        "        # Calcolo del summary\n",
        "        summary = torch.cat(valid_z_list, dim=0).mean(dim=0, keepdim=True)\n",
        "        summary = torch.tanh(summary)\n",
        "\n",
        "        return z_dict, summary\n",
        "\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        #takes the timestamp of the nodes for which we want to make predictions\n",
        "        #not the neighbours, but the nodes we want to make prediction for.\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        #this creates a dictionar for all the nodes: each nodes has its\n",
        "        #embedding\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "        #this add the temporal information to the node using the\n",
        "        #HeteroTemporalEncoder\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "        #add some other shallow embedder\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        # for edge_type, edge_index in batch.edge_index_dict.items():\n",
        "        #     print(\"model edge_tipe: \", edge_type)\n",
        "        #     print(\"model edge_index: \", edge_index)\n",
        "        #print(\"model x_dict : \", x_dict['constructors'])\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,#feature of nodes\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )#apply the gnn\n",
        "\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])#final prediction\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        # Add ID-awareness to the root node\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "NUKDGByQytF3"
      },
      "outputs": [],
      "source": [
        "class EdgePredictionModel(torch.nn.Module):\n",
        "    def __init__(self, base_model: Model):\n",
        "        super().__init__()\n",
        "        self.model=base_model\n",
        "        self.encoder = base_model.encoder\n",
        "        self.temporal_encoder = base_model.temporal_encoder\n",
        "        self.gnn = base_model.gnn\n",
        "\n",
        "    def encode(self, batch: HeteroData) -> Dict[str, Tensor]:\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        x_dict = self.gnn(x_dict, batch.edge_index_dict)\n",
        "        return x_dict\n",
        "\n",
        "    def decode(self, src_emb, dst_emb):\n",
        "        return (src_emb * dst_emb).sum(dim=1)  #dot product, calcolo similarity\n",
        "\n",
        "    def forward(self, batch: HeteroData, edge_type):\n",
        "        x_dict = self.encode(batch)\n",
        "\n",
        "        src, dst, labels = sample_edge_prediction_batch(batch, edge_type)\n",
        "\n",
        "        src_emb = x_dict[edge_type[0]][src]\n",
        "        dst_emb = x_dict[edge_type[2]][dst]\n",
        "        logits = self.decode(src_emb, dst_emb)\n",
        "\n",
        "        return logits, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MaL0--Sanwb"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "K87Ya4wPanwc"
      },
      "outputs": [],
      "source": [
        "def get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps, num_cycles=0.5):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < warmup_steps:\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "        progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * num_cycles * 2 * progress)))\n",
        "\n",
        "    return LambdaLR(optimizer, lr_lambda)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "SAHRIr15lVs6"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, scheduler) -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "id": "d0lcTAwAanwc"
      },
      "outputs": [],
      "source": [
        "def rmse(true, pred):\n",
        "    \"\"\"Calculate the Root Mean Squared Error (RMSE).\"\"\"\n",
        "    return np.sqrt(np.mean((true - pred)**2)) # Calculate RMSE manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "qZOOyAblHwI4"
      },
      "outputs": [],
      "source": [
        "def custom_evaluate(pred: np.ndarray, target_table, metrics) -> dict:\n",
        "    \"\"\"Custom evaluation function to replace task.evaluate.\"\"\"\n",
        "\n",
        "    # Extract target values from the target table\n",
        "    target = target_table.df[task.target_col].to_numpy()\n",
        "\n",
        "    # Check for length mismatch\n",
        "    if len(pred) != len(target):\n",
        "        raise ValueError(\n",
        "            f\"The length of pred and target must be the same (got \"\n",
        "            f\"{len(pred)} and {len(target)}, respectively).\"\n",
        "        )\n",
        "\n",
        "    # Calculate metrics\n",
        "    results = {}\n",
        "    for metric_fn in metrics:\n",
        "        if metric_fn.__name__ == \"rmse\":  # Handle RMSE specifically\n",
        "            results[\"rmse\"] = np.sqrt(np.mean((target - pred)**2))\n",
        "        else:  # Handle other metrics (if any)\n",
        "            results[metric_fn.__name__] = metric_fn(target, pred)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "KMn-f8dmanwc"
      },
      "outputs": [],
      "source": [
        "def training_function(model, optimizer, epochs):\n",
        "    state_dict = None\n",
        "    best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, optimizer)\n",
        "        val_pred = test(model, loader_dict[\"val\"])\n",
        "        #val_metrics = task.evaluate(val_pred, val_table)\n",
        "        val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "        #print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "        if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "        ):\n",
        "            best_val_metric = val_metrics[tune_metric]\n",
        "            state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "    print(f\"Best Val metrics for parameters {optimizer}, are: {val_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpFIqgwTanwd"
      },
      "source": [
        "## Cross validation cycle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "qLUoqMtranwd"
      },
      "outputs": [],
      "source": [
        "# #cross validation cycle:\n",
        "# #possible learning rates: [0.01, 0.001, 0.0001, 0.00001]\n",
        "# #possible batch sizes: [64, 256, 512]\n",
        "# #possible number of layers: [1, 2, 3]\n",
        "# #possible weight decay: [0.0001, 0.001, 0.01]\n",
        "\n",
        "# for lr in [0.01, 0.001, 0.0001, 0.00001]:#0.001\n",
        "#     #for batch_size in [64, 256, 512]:\n",
        "#         for num_layers in [1, 2, 3]:#1\n",
        "#             #for weight_decay in [0.0001, 0.001, 0.01]:\n",
        "#                 model = Model(\n",
        "#                     data=data,\n",
        "#                     col_stats_dict=col_stats_dict,\n",
        "#                     num_layers=num_layers,\n",
        "#                     channels=128,\n",
        "#                     out_channels=1,\n",
        "#                     aggr=\"sum\",\n",
        "#                     norm=\"batch_norm\",\n",
        "#                 ).to(device)\n",
        "#                 print(f\"Training with lr={lr}, num_layers={num_layers}\")\n",
        "#                 optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
        "#                 training_function(model, optimizer, epochs=10) # Set epochs to a smaller number for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_RxdxPHanwd"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF3W68Eqlew_",
        "outputId": "4f185710-4a56-4e24-c4c4-8a6890f70d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pretraining per edge_type: ('races', 'rev_f2p_raceId', 'standings')\n"
          ]
        }
      ],
      "source": [
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=1,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"sum\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)\n",
        "\n",
        "#copiamo i pesi del modello perché così possiamo vedere se stiamo effettivamente modificando model:\n",
        "initial_state = copy.deepcopy(model.state_dict())\n",
        "\n",
        "#pre training basato sugli archi:\n",
        "# Edge types con almeno un arco nel training set: prenderemo solo questi per il \n",
        "# pre training process:\n",
        "valid_edge_types = []\n",
        "for edge_type in data.edge_types:\n",
        "    edge_index = data[edge_type].edge_index\n",
        "    if edge_index.size(1) > 0:\n",
        "        valid_edge_types.append(edge_type)\n",
        "\n",
        "train_data = next(iter(loader_dict[\"train\"]))\n",
        "active_edge_types = [et for et in valid_edge_types if et in train_data.edge_types and train_data[et].edge_index.size(1) > 0]\n",
        "\n",
        "\n",
        "for edge_type in active_edge_types:\n",
        "    print(f\"\\nPretraining per edge_type: {edge_type}\")\n",
        "    model.load_state_dict(initial_state)\n",
        "    edge_model = EdgePredictionModel(model)\n",
        "    pretrain_optimizer = torch.optim.Adam(edge_model.parameters(), lr=0.001)\n",
        "    try:\n",
        "        pretrain_edge_prediction(edge_model, loader_dict[\"train\"], edge_type=edge_type, optimizer=pretrain_optimizer, epochs=20)\n",
        "        model.load_state_dict(edge_model.model.state_dict())  # salva pesi aggiornati\n",
        "        #break\n",
        "    except ValueError as e:\n",
        "        print(f\"skipping edge_type {edge_type}: {e}\")\n",
        "\n",
        "\n",
        "#pre training seguendo dgi:\n",
        "discriminator = DGIHead(128).to(device)\n",
        "\n",
        "optimizer_dgi = torch.optim.Adam(\n",
        "    list(model.parameters()) + list(discriminator.parameters()),\n",
        "    lr=0.001,\n",
        "    weight_decay=1e-5,\n",
        ")\n",
        "\n",
        "train_dgi(model, discriminator, optimizer_dgi, loader_dict[\"train\"], device, entity_table=entity_table, epochs=20)\n",
        "\n",
        "after_state = model.state_dict()\n",
        "\n",
        "#verifica se sono cambiati\n",
        "changed_params = [k for k in initial_state if not torch.equal(initial_state[k], after_state[k])]\n",
        "print(\"Parametri modificati:\", changed_params if changed_params else \"Nessuno è cambiato\")\n",
        "\n",
        "\n",
        "#down stream\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
        "epochs = 100\n",
        "total_steps = epochs * len(loader_dict[\"train\"])\n",
        "warmup_steps = int(0.1 * total_steps)  # 10% warmup\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "state_dict = None\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "\n",
        "#per mantenere la storia dei MAE nel tempo:\n",
        "val_metr_history = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(model, optimizer, scheduler)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    #val_metrics = task.evaluate(val_pred, val_table)\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "\n",
        "    val_metr_history.append(val_metrics[tune_metric])\n",
        "\n",
        "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "val_pred = test(model, loader_dict[\"val\"])\n",
        "val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "print(f\"Best Val metrics: {val_metrics}\")\n",
        "\n",
        "test_table = task.get_table(\"test\", mask_input_cols=False)\n",
        "test_pred = test(model,loader_dict[\"test\"])\n",
        "test_metrics = custom_evaluate(test_pred, test_table, task.metrics)\n",
        "print(f\"Best test metrics: {test_metrics}\")\n",
        "\n",
        "plot_validation_metrics([val_metr_history], [\"basic model\"],  metric_name=tune_metric)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkY-BYdoanwe"
      },
      "source": [
        "# Import a predefined model to use it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMAAXTPFanwe"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load('best_model_GAT_head2.pth', map_location=torch.device('cpu')))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
