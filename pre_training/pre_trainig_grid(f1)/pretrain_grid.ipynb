{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrea-1704/Pytorch_Geometric_tutorial/blob/main/train_model_baseline_f1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zNziUzq9nTdU"
      },
      "outputs": [],
      "source": [
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.4.0+cpu.html\n",
        "\n",
        "# !pip install pytorch_frame[full]==1.2.2\n",
        "# !pip install relbench[full]==1.0.0\n",
        "# !pip uninstall -y pyg_lib torch  # Uninstall current versions\n",
        "# !pip install torch==2.6.0  # Reinstall your desired PyTorch version\n",
        "# !pip install --no-cache-dir git+https://github.com/pyg-team/pyg-lib.git # Install pyg-lib; --no-cache-dir ensures a fresh install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOWWxUxN1U3a"
      },
      "source": [
        "New libraries to run on colab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UyHEamaV1U3b"
      },
      "outputs": [],
      "source": [
        "# !pip install torch==2.6.0+cu118 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "# !pip install torch-geometric==2.6.0 -f https://data.pyg.org/whl/torch-2.6.0+cu118.html\n",
        "\n",
        "# !pip install pytorch_frame[full]==1.2.2\n",
        "# !pip install relbench[full]==1.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
      ],
      "metadata": {
        "id": "yigMbymZe5d0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F454ta1Zg0Oq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import relbench\n",
        "import numpy as np\n",
        "from torch.nn import BCEWithLogitsLoss, L1Loss\n",
        "from relbench.datasets import get_dataset\n",
        "from relbench.tasks import get_task\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import torch_geometric\n",
        "import torch_frame\n",
        "from torch_geometric.seed import seed_everything\n",
        "from relbench.modeling.utils import get_stype_proposal\n",
        "from collections import defaultdict\n",
        "import requests\n",
        "from io import StringIO\n",
        "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
        "from relbench.modeling.graph import make_pkey_fkey_graph\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import copy\n",
        "from typing import Any, Dict, List\n",
        "from torch import Tensor\n",
        "from torch.nn import Embedding, ModuleDict\n",
        "from torch_frame.data.stats import StatType\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import MLP\n",
        "from torch_geometric.typing import NodeType\n",
        "from relbench.modeling.nn import HeteroEncoder, HeteroGraphSAGE, HeteroTemporalEncoder\n",
        "from relbench.modeling.graph import get_node_train_table_input, make_pkey_fkey_graph\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "import pyg_lib\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#per lo scheduler\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "#import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBiKBpiV1U3c"
      },
      "source": [
        "# Dataset and task creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6DWB-Kf6nl2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f09b454-1928-4c61-ba94-075ab4c421bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Loading Database object from /root/.cache/relbench/rel-f1/db...\n",
            "Done in 0.13 seconds.\n"
          ]
        }
      ],
      "source": [
        "dataset = get_dataset(\"rel-f1\", download=True)\n",
        "task = get_task(\"rel-f1\", \"driver-position\", download=True)\n",
        "\n",
        "train_table = task.get_table(\"train\")\n",
        "val_table = task.get_table(\"val\")\n",
        "test_table = task.get_table(\"test\")\n",
        "\n",
        "out_channels = 1\n",
        "# one because we are estimating one single value.\n",
        "loss_fn = L1Loss()\n",
        "# this is the mae loss and is used when have regressions tasks.\n",
        "tune_metric = \"mae\"\n",
        "higher_is_better = False\n",
        "\n",
        "seed_everything(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "root_dir = \"./data\"\n",
        "\n",
        "db = dataset.get_db()\n",
        "col_to_stype_dict = get_stype_proposal(db)\n",
        "#this is used to get the stype of the columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElqMK-iU1U3d"
      },
      "source": [
        "# Embedder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QQHYmgIxkX1j"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from typing import List, Optional\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# from torch import Tensor\n",
        "\n",
        "\n",
        "# class GloveTextEmbedding:\n",
        "#     def __init__(self, device: Optional[torch.device\n",
        "#                                        ] = None):\n",
        "#         self.model = SentenceTransformer(\n",
        "#             \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
        "#             device=device,\n",
        "#         )\n",
        "\n",
        "#     def __call__(self, sentences: List[str]) -> Tensor:\n",
        "#         return torch.from_numpy(self.model.encode(sentences))\n",
        "\n",
        "\n",
        "class LightweightGloveEmbedder:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device\n",
        "        self.embeddings = defaultdict(lambda: np.zeros(300))\n",
        "        self._load_embeddings()\n",
        "\n",
        "    def _load_embeddings(self):\n",
        "        try:\n",
        "            #(senza bisogno di estrarre zip\n",
        "            url = \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt\"\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            for line in StringIO(response.text):\n",
        "                parts = line.split()\n",
        "                word = parts[0]\n",
        "                vector = np.array(parts[1:], dtype=np.float32)\n",
        "                self.embeddings[word] = vector\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Couldn't load GloVe embeddings ({str(e)}). Using zero vectors.\")\n",
        "\n",
        "    def __call__(self, sentences):\n",
        "        results = []\n",
        "        for text in sentences:\n",
        "            words = text.lower().split()\n",
        "            vectors = [self.embeddings[w] for w in words if w in self.embeddings]\n",
        "            if vectors:\n",
        "                avg_vector = np.mean(vectors, axis=0)\n",
        "            else:\n",
        "                avg_vector = np.zeros(300)\n",
        "            results.append(avg_vector)\n",
        "\n",
        "        tensor = torch.tensor(np.array(results), dtype=torch.float32)\n",
        "        return tensor.to(self.device) if self.device else tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-BBpUrakdwY",
        "outputId": "d1372a63-ad62-4d3d-af50-b8ac9c5db622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Couldn't load GloVe embeddings (404 Client Error: Not Found for url: https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.300d.txt). Using zero vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n",
            "/usr/local/lib/python3.11/dist-packages/torch_frame/utils/io.py:113: UserWarning: Weights only load failed. Please file an issue to make `torch.load(weights_only=True)` compatible in your case. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global.\n",
            "  warnings.warn(f\"{warn_msg} Please use \"\n"
          ]
        }
      ],
      "source": [
        "text_embedder_cfg = TextEmbedderConfig(\n",
        "    text_embedder=LightweightGloveEmbedder(device=device), batch_size=256\n",
        ")\n",
        "\n",
        "data, col_stats_dict = make_pkey_fkey_graph(\n",
        "    #Solution if not working: !pip install --upgrade torch torchvision transformers\n",
        "    db,\n",
        "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
        "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
        "    cache_dir=os.path.join(\n",
        "        root_dir, f\"rel-f1_materialized_cache\"\n",
        "    ),  # store materialized graph for convenience\n",
        ")# create a graph how relbench requires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HUHVG-g6lM-b"
      },
      "outputs": [],
      "source": [
        "loader_dict = {}\n",
        "\n",
        "for split, table in [\n",
        "    (\"train\", train_table),\n",
        "    (\"val\", val_table),\n",
        "    (\"test\", test_table),\n",
        "]:\n",
        "    table_input = get_node_train_table_input(\n",
        "        table=table,\n",
        "        task=task,\n",
        "    )#notice that table_input is an object with three elements: nodes, time and transform.\n",
        "    #nodes contains the input nodes\n",
        "    #time contains the time for each node\n",
        "    #transform is the tranformation to be applied to nodes\n",
        "    entity_table = table_input.nodes[0]\n",
        "    #we need to populate the loader_dict with three elements: \"train\", \"val\", and \"test\".\n",
        "    loader_dict[split] = NeighborLoader(\n",
        "        data,\n",
        "        num_neighbors=[\n",
        "            128 for i in range(2)\n",
        "        ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
        "        time_attr=\"time\",\n",
        "        input_nodes=table_input.nodes,\n",
        "        input_time=table_input.time,\n",
        "        transform=table_input.transform,\n",
        "        batch_size=512,\n",
        "        temporal_strategy=\"uniform\",\n",
        "        shuffle=split == \"train\",\n",
        "        num_workers=0,\n",
        "        persistent_workers=False,\n",
        "    )#this is the loader for grapg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J2qIPMh1U3e"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_gyC-hV1U3e"
      },
      "source": [
        "## graphormer layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aKifOjNW1U3g"
      },
      "outputs": [],
      "source": [
        "_spatial_bias_cache = None\n",
        "_node_offset_cache = None\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def compute_spatial_bias(edge_index_dict, x_dict):\n",
        "    global _spatial_bias_cache, _node_offset_cache\n",
        "    if _spatial_bias_cache is not None:\n",
        "        return _spatial_bias_cache, _node_offset_cache\n",
        "    #creiamo un grafo diretto con Networkx\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    node_offset = {}\n",
        "    curr_offset = 0\n",
        "\n",
        "    #aggiungiamo i nodi con offset per mantenere indici globali univoci\n",
        "    for node_type, x in x_dict.items():\n",
        "        node_offset[node_type] = curr_offset\n",
        "        for i in range(x.size(0)):\n",
        "            G.add_node(curr_offset + i, type=node_type)\n",
        "        curr_offset += x.size(0)\n",
        "\n",
        "    #Aggiungiamo gli archi con offset\n",
        "    for (src_type, _, dst_type), edge_index in edge_index_dict.items():\n",
        "        src_offset = node_offset[src_type]\n",
        "        dst_offset = node_offset[dst_type]\n",
        "        src, dst = edge_index\n",
        "        for s, d in zip(src.tolist(), dst.tolist()):\n",
        "            G.add_edge(src_offset + s, dst_offset + d)\n",
        "\n",
        "\n",
        "    spatial_bias = defaultdict(lambda: -1)\n",
        "\n",
        "\n",
        "\n",
        "    for node in G.nodes():\n",
        "        lengths = nx.single_source_dijkstra_path_length(G, node)\n",
        "        for target, dist in lengths.items():\n",
        "            spatial_bias[(node, target)] = dist\n",
        "        #quelli non raggiungibili li lasciamo con default value, ovvero -1\n",
        "\n",
        "    _spatial_bias_cache = spatial_bias\n",
        "    _node_offset_cache = node_offset\n",
        "\n",
        "    return spatial_bias, node_offset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CBqSsq2C1U3g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import Linear\n",
        "from torch_geometric.utils import softmax\n",
        "from torch_geometric.utils import degree\n",
        "from collections import defaultdict\n",
        "\n",
        "class HeteroGraphormerLayerComplete(nn.Module):\n",
        "    def __init__(self, channels, edge_types, device, num_heads=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.num_heads = num_heads\n",
        "        self.channels = channels\n",
        "        self.head_dim = channels // num_heads\n",
        "\n",
        "        assert self.channels % num_heads == 0, \"channels must be divisible by num_heads\"\n",
        "\n",
        "        self.q_lin = Linear(channels, channels)\n",
        "        self.k_lin = Linear(channels, channels)\n",
        "        self.v_lin = Linear(channels, channels)\n",
        "        self.out_lin = Linear(channels, channels)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = nn.LayerNorm(channels)\n",
        "\n",
        "        self.edge_type_bias = nn.ParameterDict({\n",
        "            \"__\".join(edge_type): nn.Parameter(torch.randn(1))\n",
        "            for edge_type in edge_types\n",
        "        })\n",
        "\n",
        "    def compute_total_degrees(self, x_dict, edge_index_dict):\n",
        "        device = self.device\n",
        "        in_deg = defaultdict(lambda: torch.zeros(0, device=device))\n",
        "        out_deg = defaultdict(lambda: torch.zeros(0, device=device))\n",
        "        for edge_type, edge_index in edge_index_dict.items():\n",
        "            src_type, _, dst_type = edge_type\n",
        "            src = edge_index[0]\n",
        "            dst = edge_index[1]\n",
        "\n",
        "            num_src = x_dict[src_type].size(0)\n",
        "            num_dst = x_dict[dst_type].size(0)\n",
        "\n",
        "            if out_deg[src_type].numel() == 0:\n",
        "                out_deg[src_type] = torch.zeros(num_src, device=device)\n",
        "            if in_deg[dst_type].numel() == 0:\n",
        "                in_deg[dst_type] = torch.zeros(num_dst, device=device)\n",
        "\n",
        "            out_deg[src_type] += degree(src, num_nodes=num_src)\n",
        "            in_deg[dst_type]  += degree(dst, num_nodes=num_dst)\n",
        "\n",
        "        total_deg = {\n",
        "            node_type: in_deg[node_type] + out_deg[node_type]\n",
        "            for node_type in x_dict\n",
        "        }\n",
        "\n",
        "        return total_deg\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        self.spatial_bias, self.node_offset = compute_spatial_bias(edge_index_dict, x_dict)\n",
        "\n",
        "        out_dict = {k: torch.zeros_like(v) for k, v in x_dict.items()}\n",
        "        for edge_type, edge_index in edge_index_dict.items():\n",
        "            src_type, _, dst_type = edge_type\n",
        "            x_src, x_dst = x_dict[src_type], x_dict[dst_type]\n",
        "\n",
        "            #src, dst = edge_index\n",
        "            src = edge_index[0]\n",
        "            dst = edge_index[1]\n",
        "\n",
        "            Q = self.q_lin(x_dst).view(-1, self.num_heads, self.head_dim)\n",
        "            K = self.k_lin(x_src).view(-1, self.num_heads, self.head_dim)\n",
        "            V = self.v_lin(x_src).view(-1, self.num_heads, self.head_dim)\n",
        "\n",
        "            attn_scores = (Q[dst] * K[src]).sum(dim=-1) / self.head_dim**0.5\n",
        "            src_offset = self.node_offset[src_type]\n",
        "            dst_offset = self.node_offset[dst_type]\n",
        "\n",
        "            spatial_bias_vals = []\n",
        "            for s, d in zip(src.tolist(), dst.tolist()):\n",
        "                global_s = src_offset + s\n",
        "                global_d = dst_offset + d\n",
        "                dist = self.spatial_bias.get((global_d, global_s), -1.0)\n",
        "                spatial_bias_vals.append(dist)\n",
        "\n",
        "            spatial_bias_tensor = torch.tensor(spatial_bias_vals, dtype=torch.float, device=self.device)\n",
        "            attn_scores = attn_scores + spatial_bias_tensor.unsqueeze(-1)\n",
        "\n",
        "            bias_name = \"__\".join(edge_type)\n",
        "            attn_scores = attn_scores + self.edge_type_bias[bias_name]\n",
        "\n",
        "            attn_weights = softmax(attn_scores, dst)\n",
        "            attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "            out = V[src] * attn_weights.unsqueeze(-1)\n",
        "            out = out.view(-1, self.channels)\n",
        "\n",
        "            out_dict[dst_type].index_add_(0, dst, out)\n",
        "\n",
        "        total_deg = self.compute_total_degrees(x_dict, edge_index_dict)\n",
        "\n",
        "        for node_type in out_dict:\n",
        "            # Assicurati che total_deg[node_type] sia della forma corretta (num_nodes, 1)\n",
        "            degree_embed = total_deg[node_type].view(-1, 1)                                                                                  # Assicurati che sia una colonna\n",
        "            degree_embed = degree_embed.expand(-1, self.channels)                                                                            # Espandi lungo la dimensione dei canali\n",
        "\n",
        "            # Somma l'embedding con la degree centrality\n",
        "            out_dict[node_type] = out_dict[node_type] + degree_embed\n",
        "\n",
        "        # Normalizzazione finale\n",
        "        for node_type in out_dict:\n",
        "            out_dict[node_type] = self.norm(out_dict[node_type] + x_dict[node_type])\n",
        "\n",
        "        return out_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR6g_lwH1U3h"
      },
      "source": [
        "## HeteroGraphormer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0rbfjsM51U3h"
      },
      "outputs": [],
      "source": [
        "class HeteroGraphormer(torch.nn.Module):\n",
        "    def __init__(self, node_types, edge_types, channels, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.ModuleList([\n",
        "            HeteroGraphormerLayerComplete(channels, edge_types, device) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, *args, **kwargs):\n",
        "        for layer in self.layers:\n",
        "            x_dict = layer(x_dict, edge_index_dict)\n",
        "        return x_dict\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for layer in self.layers:\n",
        "            if hasattr(layer, \"reset_parameters\"):\n",
        "                layer.reset_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u3m3jEqClQnw"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: HeteroData, #notice that \"data2 is the graph we created with function make_pkey_fkey_graph\n",
        "        col_stats_dict: Dict[str, Dict[str, Dict[StatType, Any]]],\n",
        "        num_layers: int,\n",
        "        channels: int,\n",
        "        out_channels: int,\n",
        "        aggr: str,\n",
        "        norm: str,\n",
        "        # List of node types to add shallow embeddings to input\n",
        "        shallow_list: List[NodeType] = [],\n",
        "        # ID awareness\n",
        "        id_awareness: bool = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = HeteroEncoder(\n",
        "            channels=channels,\n",
        "            node_to_col_names_dict={\n",
        "                node_type: data[node_type].tf.col_names_dict\n",
        "                for node_type in data.node_types\n",
        "            },\n",
        "            node_to_col_stats=col_stats_dict,\n",
        "        )\n",
        "        self.temporal_encoder = HeteroTemporalEncoder(\n",
        "            node_types=[\n",
        "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
        "            ],\n",
        "            channels=channels,\n",
        "        )\n",
        "        self.gnn = HeteroGraphormer(\n",
        "            node_types=data.node_types,\n",
        "            edge_types=data.edge_types,\n",
        "            channels=channels,\n",
        "            num_layers=num_layers,\n",
        "        )\n",
        "        self.head = MLP(\n",
        "            channels,#one, since we are doing regression\n",
        "            out_channels=out_channels,\n",
        "            norm=norm,\n",
        "            num_layers=1,\n",
        "        )\n",
        "        self.embedding_dict = ModuleDict(\n",
        "            {\n",
        "                node: Embedding(data.num_nodes_dict[node], channels)\n",
        "                for node in shallow_list\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.id_awareness_emb = None\n",
        "        if id_awareness:\n",
        "            self.id_awareness_emb = torch.nn.Embedding(1, channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.encoder.reset_parameters()\n",
        "        self.temporal_encoder.reset_parameters()\n",
        "        self.gnn.reset_parameters()\n",
        "        self.head.reset_parameters()\n",
        "        for embedding in self.embedding_dict.values():\n",
        "            torch.nn.init.normal_(embedding.weight, std=0.1)\n",
        "        if self.id_awareness_emb is not None:\n",
        "            self.id_awareness_emb.reset_parameters()\n",
        "\n",
        "    def forward_for_embedding(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        # Come la forward ma senza usare seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "\n",
        "        # Se c'è l'embedding ID-aware lo aggiungiamo\n",
        "        if self.id_awareness_emb is not None:\n",
        "            for node_type in x_dict:\n",
        "                x_dict[node_type] += self.id_awareness_emb.weight\n",
        "\n",
        "        if hasattr(batch[entity_table], \"time\"):  # fallback se vuoi usare il tempo\n",
        "            rel_time_dict = self.temporal_encoder(\n",
        "                batch[entity_table].time,  # oppure seed_time se esiste\n",
        "                batch.time_dict,\n",
        "                batch.batch_dict,\n",
        "            )\n",
        "            for node_type, rel_time in rel_time_dict.items():\n",
        "                x_dict[node_type] += rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] += embedding(batch[node_type].n_id)\n",
        "\n",
        "        z_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )\n",
        "\n",
        "        return z_dict[entity_table]  # restituisce tutti gli embeddings per quel nodo\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        #takes the timestamp of the nodes for which we want to make predictions\n",
        "        #not the neighbours, but the nodes we want to make prediction for.\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        #this creates a dictionar for all the nodes: each nodes has its\n",
        "        #embedding\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "        #this add the temporal information to the node using the\n",
        "        #HeteroTemporalEncoder\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "        #add some other shallow embedder\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,#feature of nodes\n",
        "            batch.edge_index_dict,\n",
        "            batch.num_sampled_nodes_dict,\n",
        "            batch.num_sampled_edges_dict,\n",
        "        )#apply the gnn\n",
        "\n",
        "        return self.head(x_dict[entity_table][: seed_time.size(0)])#final prediction\n",
        "\n",
        "    def forward_dst_readout(\n",
        "        self,\n",
        "        batch: HeteroData,\n",
        "        entity_table: NodeType,\n",
        "        dst_table: NodeType,\n",
        "    ) -> Tensor:\n",
        "        if self.id_awareness_emb is None:\n",
        "            raise RuntimeError(\n",
        "                \"id_awareness must be set True to use forward_dst_readout\"\n",
        "            )\n",
        "        seed_time = batch[entity_table].seed_time\n",
        "        x_dict = self.encoder(batch.tf_dict)\n",
        "        # Add ID-awareness to the root node\n",
        "        x_dict[entity_table][: seed_time.size(0)] += self.id_awareness_emb.weight\n",
        "\n",
        "        rel_time_dict = self.temporal_encoder(\n",
        "            seed_time, batch.time_dict, batch.batch_dict\n",
        "        )\n",
        "\n",
        "        for node_type, rel_time in rel_time_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + rel_time\n",
        "\n",
        "        for node_type, embedding in self.embedding_dict.items():\n",
        "            x_dict[node_type] = x_dict[node_type] + embedding(batch[node_type].n_id)\n",
        "\n",
        "        x_dict = self.gnn(\n",
        "            x_dict,\n",
        "            batch.edge_index_dict,\n",
        "        )\n",
        "\n",
        "        return self.head(x_dict[dst_table])\n",
        "\n",
        "\n",
        "model = Model(\n",
        "    data=data,\n",
        "    col_stats_dict=col_stats_dict,\n",
        "    num_layers=2,\n",
        "    channels=128,\n",
        "    out_channels=1,\n",
        "    aggr=\"sum\",\n",
        "    norm=\"batch_norm\",\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl-6So7Llb-p"
      },
      "source": [
        "We also need standard train/test loops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre training task\n",
        "As a pre training task we would now want to implement a task that is correlated to the real task. What we will do is trying to estimate the \"**grid**\" value out of the trainig records."
      ],
      "metadata": {
        "id": "EawhgvXG1uRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === MODELLO PER PRE-TRAINING SUL GRID ===\n",
        "\n",
        "class GraphormerPretrainGrid(nn.Module):\n",
        "    def __init__(self, graphormer_model, embedding_dim, hidden_dim=128):\n",
        "        super(GraphormerPretrainGrid, self).__init__()\n",
        "        self.graphormer = graphormer_model\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1)  #predice il valore continuo del GRID\n",
        "        )\n",
        "\n",
        "    def forward(self, batch, entity_table='results'):\n",
        "        #estrae embeddings dal modello Graphormer\n",
        "        embeddings = self.graphormer.forward_for_embedding(batch, entity_table=entity_table)\n",
        "\n",
        "        if embeddings is None or len(embeddings) == 0:\n",
        "            return None\n",
        "\n",
        "        #predice il valore di GRID\n",
        "        output = self.regressor(embeddings)\n",
        "        return output.squeeze()  #ottenere un vettore 1D\n"
      ],
      "metadata": {
        "id": "RmGx3uOU2A8W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pre training function"
      ],
      "metadata": {
        "id": "eRkxm09h2RAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pretrain_grid_loop(\n",
        "    model,\n",
        "    optimizer,\n",
        "    loader,\n",
        "    loss_fn,\n",
        "    device=\"cuda\",\n",
        "    entity_table=\"results\"\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_count = 0\n",
        "\n",
        "    for batch in tqdm(loader):\n",
        "        #print(batch[entity_table].keys())\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch, entity_table=entity_table)\n",
        "        if predictions is None:\n",
        "            continue\n",
        "\n",
        "        tf = batch[entity_table].tf\n",
        "\n",
        "        # Troviamo la chiave numerica\n",
        "        numerical_key = None\n",
        "        for key in tf.col_names_dict.keys():\n",
        "            if \"numerical\" in str(key):\n",
        "                numerical_key = key\n",
        "                break\n",
        "        assert numerical_key is not None, \"Errore: tipo numerico non trovato!\"\n",
        "\n",
        "        # Trova l'indice di 'grid'\n",
        "        grid_idx = tf.col_names_dict[numerical_key].index('grid')\n",
        "        all_grid = tf.feat_dict[numerical_key][:, grid_idx]\n",
        "\n",
        "        # Prendi solo i nodi centrali del batch\n",
        "        mask = batch[entity_table].batch == 0\n",
        "\n",
        "        # Costruisci targets\n",
        "        targets = (all_grid[mask] / 30.0).float().to(device)\n",
        "        if predictions[mask].numel() == 0 or targets.numel() == 0:\n",
        "          continue  # Skippa batch vuoto\n",
        "\n",
        "        # >>>>>> QUI LA CORREZIONE\n",
        "        loss = loss_fn(predictions[mask], targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if torch.isnan(loss):\n",
        "            print(\"Loss contiene NaN!\")\n",
        "            break\n",
        "\n",
        "        if torch.isinf(loss):\n",
        "            print(\"Loss contiene Inf!\")\n",
        "            break\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_count += 1\n",
        "\n",
        "    return total_loss / total_count if total_count > 0 else 0.0\n"
      ],
      "metadata": {
        "id": "-sFuG51o2S4S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlR9IuwW1U3i"
      },
      "source": [
        "### Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zm1uM_ij1U3i"
      },
      "outputs": [],
      "source": [
        "def get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps, num_cycles=0.5):\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < warmup_steps:\n",
        "            return float(current_step) / float(max(1, warmup_steps))\n",
        "        progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * num_cycles * 2 * progress)))\n",
        "\n",
        "    return LambdaLR(optimizer, lr_lambda)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Py_olFY1U3i"
      },
      "source": [
        "Dobbiamo modificare la funzione di training in modo da ricevere correttamente uno scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SAHRIr15lVs6"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, scheduler) -> float:\n",
        "    model.train()\n",
        "\n",
        "    loss_accum = count_accum = 0\n",
        "    for batch in tqdm(loader_dict[\"train\"]):\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "#        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        pred = pred.view(-1) if pred.dim() == 2 and pred.size(1) == 1 else pred\n",
        "\n",
        "\n",
        "        loss = loss_fn(pred.float(), batch[entity_table].y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        loss_accum += loss.detach().item() * pred.size(0)\n",
        "        count_accum += pred.size(0)\n",
        "\n",
        "    return loss_accum / count_accum\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, loader: NeighborLoader) -> np.ndarray:\n",
        "    model.eval()\n",
        "\n",
        "    pred_list = []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        pred = model(\n",
        "            batch,\n",
        "            task.entity_table,\n",
        "        )\n",
        "        #pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
        "        if pred.dim() == 2 and pred.size(1) == 1:\n",
        "           pred = pred.view(-1)\n",
        "\n",
        "        pred_list.append(pred.detach().cpu())\n",
        "    return torch.cat(pred_list, dim=0).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iRKOx4Wf1U3i"
      },
      "outputs": [],
      "source": [
        "def rmse(true, pred):\n",
        "    \"\"\"Calculate the Root Mean Squared Error (RMSE).\"\"\"\n",
        "    return np.sqrt(np.mean((true - pred)**2)) # Calculate RMSE manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qZOOyAblHwI4"
      },
      "outputs": [],
      "source": [
        "def custom_evaluate(pred: np.ndarray, target_table, metrics) -> dict:\n",
        "    \"\"\"Custom evaluation function to replace task.evaluate.\"\"\"\n",
        "\n",
        "    # Extract target values from the target table\n",
        "    target = target_table.df[task.target_col].to_numpy()\n",
        "\n",
        "    # Check for length mismatch\n",
        "    if len(pred) != len(target):\n",
        "        raise ValueError(\n",
        "            f\"The length of pred and target must be the same (got \"\n",
        "            f\"{len(pred)} and {len(target)}, respectively).\"\n",
        "        )\n",
        "\n",
        "    # Calculate metrics\n",
        "    results = {}\n",
        "    for metric_fn in metrics:\n",
        "        if metric_fn.__name__ == \"rmse\":  # Handle RMSE specifically\n",
        "            results[\"rmse\"] = np.sqrt(np.mean((target - pred)**2))\n",
        "        else:  # Handle other metrics (if any)\n",
        "            results[metric_fn.__name__] = metric_fn(target, pred)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KkWi72Qd1U3m"
      },
      "outputs": [],
      "source": [
        "def training_function(model, optimizer, epochs):\n",
        "    state_dict = None\n",
        "    best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train(model, optimizer)\n",
        "        val_pred = test(model, loader_dict[\"val\"])\n",
        "        #val_metrics = task.evaluate(val_pred, val_table)\n",
        "        val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "        #print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "        if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "        ):\n",
        "            best_val_metric = val_metrics[tune_metric]\n",
        "            state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "    model.load_state_dict(state_dict)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "    print(f\"Best Val metrics for parameters {optimizer}, are: {val_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMnS7MFx1U3m"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5DlP_AT1U3n"
      },
      "source": [
        "Andiamo a plottare i valori delle metriche durante il training per avere una visione più avanzata su come stia procedendo il processo di training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iwt_B51N1U3n"
      },
      "outputs": [],
      "source": [
        "def plot_validation_metrics(metric_histories, model_names=None, metric_name=\"MAE\", informationsTitle=\"\"):\n",
        "    \"\"\"\n",
        "    Plotta l'andamento del metric_name per più modelli nel tempo.\n",
        "\n",
        "    Args:\n",
        "        metric_histories (list of lists): Lista di liste, ognuna rappresenta i valori di metriche per un modello.\n",
        "        model_names (list of str): Nomi dei modelli (opzionale).\n",
        "        metric_name (str): Nome della metrica da visualizzare.\n",
        "        informationsTitle (str): info aggiungitive da mettere nel titolo (conf generale dei parametri ecc).\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(9, 5))\n",
        "\n",
        "    if model_names is None:\n",
        "        model_names = [f\"Model {i+1}\" for i in range(len(metric_histories))]\n",
        "\n",
        "    for metrics, name in zip(metric_histories, model_names):\n",
        "        plt.plot(metrics, marker='o', label=f'{name} {metric_name}')\n",
        "\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.title(f\"{metric_name} over Epochs for Multiple Models {informationsTitle}\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yF3W68Eqlew_",
        "outputId": "a568b4a2-6141-40e5-ff04-becf0160b04a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:31<00:00,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 - Pretraining Loss: 0.224706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50 - Pretraining Loss: 0.076539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/50 - Pretraining Loss: 0.081271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50 - Pretraining Loss: 0.050121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/50 - Pretraining Loss: 0.056752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/50 - Pretraining Loss: 0.055561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/50 - Pretraining Loss: 0.013576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/50 - Pretraining Loss: 0.012018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/50 - Pretraining Loss: 0.008822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50 - Pretraining Loss: 0.009171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/50 - Pretraining Loss: 0.009387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/50 - Pretraining Loss: 0.013072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50 - Pretraining Loss: 0.026082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50 - Pretraining Loss: 0.039244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/50 - Pretraining Loss: 0.034889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/50 - Pretraining Loss: 0.016668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/50 - Pretraining Loss: 0.020071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/50 - Pretraining Loss: 0.009681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/50 - Pretraining Loss: 0.007768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/50 - Pretraining Loss: 0.007454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/50 - Pretraining Loss: 0.006138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:07<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50 - Pretraining Loss: 0.007474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/50 - Pretraining Loss: 0.012103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/50 - Pretraining Loss: 0.010313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/50 - Pretraining Loss: 0.008781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/50 - Pretraining Loss: 0.006527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/50 - Pretraining Loss: 0.003290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/50 - Pretraining Loss: 0.003844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/50 - Pretraining Loss: 0.005461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/50 - Pretraining Loss: 0.007037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/50 - Pretraining Loss: 0.005729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/50 - Pretraining Loss: 0.003685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/50 - Pretraining Loss: 0.002941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/50 - Pretraining Loss: 0.002674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:06<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/50 - Pretraining Loss: 0.002954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/50 - Pretraining Loss: 0.005378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/50 - Pretraining Loss: 0.010094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/50 - Pretraining Loss: 0.009447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/50 - Pretraining Loss: 0.010884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/50 - Pretraining Loss: 0.009141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50 - Pretraining Loss: 0.005266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/50 - Pretraining Loss: 0.006090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/50 - Pretraining Loss: 0.004172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/50 - Pretraining Loss: 0.005368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/50 - Pretraining Loss: 0.004211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/50 - Pretraining Loss: 0.003790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/50 - Pretraining Loss: 0.003754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/50 - Pretraining Loss: 0.011727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/50 - Pretraining Loss: 0.008813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/50 - Pretraining Loss: 0.008509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/15 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-bb848b19410b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m#val_metrics = task.evaluate(val_pred, val_table)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-bccdbf066c40>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         )\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentity_table\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "model = Model(\n",
        "                    data=data,\n",
        "                    col_stats_dict=col_stats_dict,\n",
        "                    num_layers=1,\n",
        "                    channels=128,\n",
        "                    out_channels=1,\n",
        "                    aggr=\"sum\",\n",
        "                    norm=\"batch_norm\",\n",
        "                ).to(device)\n",
        "\n",
        "#####PRE TRAINING####\n",
        "embedding_dim = 128\n",
        "model = GraphormerPretrainGrid(graphormer_model=model, embedding_dim=embedding_dim).to(device)\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "table =  train_table.df\n",
        "epochs = 50\n",
        "train_losses = []\n",
        "for epoch in range(epochs):\n",
        "    loss = pretrain_grid_loop(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        loader=loader_dict[\"train\"],\n",
        "        loss_fn=loss_fn,\n",
        "        device=device\n",
        "    )\n",
        "    train_losses.append(loss)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Pretraining Loss: {loss:.6f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#####TRAINING####\n",
        "epochs = 30\n",
        "total_steps = epochs * len(loader_dict[\"train\"])\n",
        "warmup_steps = int(0.1 * total_steps)  # 10% warmup\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "state_dict = None\n",
        "best_val_metric = -math.inf if higher_is_better else math.inf\n",
        "\n",
        "#per mantenere la storia dei MAE nel tempo:\n",
        "val_metr_history = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss = train(model, optimizer, scheduler)\n",
        "    val_pred = test(model, loader_dict[\"val\"])\n",
        "    #val_metrics = task.evaluate(val_pred, val_table)\n",
        "    val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "\n",
        "    val_metr_history.append(val_metrics[tune_metric])\n",
        "\n",
        "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
        "\n",
        "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
        "            not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
        "    ):\n",
        "        best_val_metric = val_metrics[tune_metric]\n",
        "        state_dict = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "val_pred = test(model, loader_dict[\"val\"])\n",
        "val_metrics = custom_evaluate(val_pred, val_table, task.metrics)\n",
        "print(f\"Best Val metrics: {val_metrics}\")\n",
        "\n",
        "test_table = task.get_table(\"test\", mask_input_cols=False)\n",
        "test_pred = test(model,loader_dict[\"test\"])\n",
        "test_metrics = custom_evaluate(test_pred, test_table, task.metrics)\n",
        "print(f\"Best test metrics: {test_metrics}\")\n",
        "\n",
        "plot_validation_metrics([val_metr_history], [\"basic model\"],  metric_name=tune_metric)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-51t8n3XltMQ",
        "outputId": "d31fd24f-d1a6-4884-cae1-3586a434de0c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Train loss: 153.76482490141345, Val metrics: {'r2': -0.8950842194482898, 'mae': 5.344049803288523, 'rmse': np.float64(6.3821138495123035)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 02, Train loss: 65.68823378130556, Val metrics: {'r2': -0.9340353907629046, 'mae': 5.167217936162242, 'rmse': np.float64(6.447368574719857)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 03, Train loss: 49.41835264172408, Val metrics: {'r2': 0.016312783676602827, 'mae': 3.773888968911741, 'rmse': np.float64(4.598104142318502)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 04, Train loss: 42.755318699883695, Val metrics: {'r2': 0.20979012994019586, 'mae': 3.318544458275886, 'rmse': np.float64(4.121179345644733)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 05, Train loss: 38.97677477897133, Val metrics: {'r2': 0.2160690068257186, 'mae': 3.344431697868393, 'rmse': np.float64(4.104773586676112)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 06, Train loss: 37.96216105915757, Val metrics: {'r2': 0.19025258795033384, 'mae': 3.362862693491026, 'rmse': np.float64(4.171815313787828)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 07, Train loss: 37.19786448435833, Val metrics: {'r2': 0.2217656443061019, 'mae': 3.281184003571311, 'rmse': np.float64(4.089832193419984)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 08, Train loss: 36.21781262093609, Val metrics: {'r2': 0.22971819286267414, 'mae': 3.2604556015514103, 'rmse': np.float64(4.068882137731502)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 09, Train loss: 35.521013180809376, Val metrics: {'r2': 0.2808509953947309, 'mae': 3.158390213603884, 'rmse': np.float64(3.931513139538221)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10, Train loss: 35.43206730756474, Val metrics: {'r2': 0.25449293982408117, 'mae': 3.2274841453205685, 'rmse': np.float64(4.002913173332664)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11, Train loss: 35.09024359200059, Val metrics: {'r2': 0.18419611341495645, 'mae': 3.409950949274546, 'rmse': np.float64(4.187387715601239)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12, Train loss: 35.08271061979043, Val metrics: {'r2': 0.22952413312935627, 'mae': 3.2736837029695987, 'rmse': np.float64(4.069394649158782)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13, Train loss: 34.64559677535538, Val metrics: {'r2': 0.2732541495605133, 'mae': 3.167787153145912, 'rmse': np.float64(3.9522241719071785)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14, Train loss: 34.497343140897314, Val metrics: {'r2': 0.24621663527723592, 'mae': 3.229521861550962, 'rmse': np.float64(4.025071171675374)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15, Train loss: 34.6439990050422, Val metrics: {'r2': 0.22553512243539386, 'mae': 3.2681564956007594, 'rmse': np.float64(4.079915356524933)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16, Train loss: 34.20005244330945, Val metrics: {'r2': 0.245865665675023, 'mae': 3.2205230699512426, 'rmse': np.float64(4.026008120733236)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17, Train loss: 33.867303352555574, Val metrics: {'r2': 0.25945225187783927, 'mae': 3.190631388980863, 'rmse': np.float64(3.989576733225038)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18, Train loss: 33.65388621948684, Val metrics: {'r2': 0.2670989186180355, 'mae': 3.189810723627737, 'rmse': np.float64(3.9689257189046727)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:06<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19, Train loss: 33.547575137958454, Val metrics: {'r2': 0.23376912746265766, 'mae': 3.295276414543769, 'rmse': np.float64(4.058168848579631)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20, Train loss: 33.27948648536444, Val metrics: {'r2': 0.21422801835631833, 'mae': 3.3287302703322292, 'rmse': np.float64(4.109590598298994)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21, Train loss: 33.39979883048353, Val metrics: {'r2': 0.22834557614151696, 'mae': 3.2902825984942097, 'rmse': np.float64(4.072505830867563)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22, Train loss: 33.22059830809286, Val metrics: {'r2': 0.23649117699113176, 'mae': 3.2513046313064766, 'rmse': np.float64(4.050954074795835)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23, Train loss: 33.04540200273767, Val metrics: {'r2': 0.2252221465860712, 'mae': 3.27208607953313, 'rmse': np.float64(4.080739658588571)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24, Train loss: 32.97396513799301, Val metrics: {'r2': 0.21055150521787547, 'mae': 3.30711909926726, 'rmse': np.float64(4.1191934679881514)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25, Train loss: 32.82144456272491, Val metrics: {'r2': 0.2132485355693875, 'mae': 3.310052220695562, 'rmse': np.float64(4.112151150042208)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26, Train loss: 32.676979195459026, Val metrics: {'r2': 0.21362503862535676, 'mae': 3.3003385030992365, 'rmse': np.float64(4.111167089117161)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27, Train loss: 32.61190042683826, Val metrics: {'r2': 0.20896130900803633, 'mae': 3.311277261860146, 'rmse': np.float64(4.123340052977794)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:05<00:00,  2.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28, Train loss: 32.52021255247484, Val metrics: {'r2': 0.20655811087074982, 'mae': 3.310582998233711, 'rmse': np.float64(4.129598715510703)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29, Train loss: 32.655457615772384, Val metrics: {'r2': 0.20377125854542155, 'mae': 3.3234168371838892, 'rmse': np.float64(4.136844673962563)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [00:04<00:00,  3.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30, Train loss: 32.53728518427802, Val metrics: {'r2': 0.2069998512094916, 'mae': 3.3151365217082724, 'rmse': np.float64(4.12844900036862)}\n",
            "Best Val metrics: {'r2': 0.2802804306750709, 'mae': 3.159278554540518, 'rmse': np.float64(3.933072439436699)}\n",
            "Best test metrics: {'r2': 0.16420793723282145, 'mae': 3.852445197900136, 'rmse': np.float64(4.763421110870863)}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}